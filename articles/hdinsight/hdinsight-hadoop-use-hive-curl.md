<properties
   pageTitle="Χρήση της ομάδας Hadoop με καμπύλη στο HDInsight | Microsoft Azure"
   description="Μάθετε πώς μπορείτε να υποβάλλουν από απόσταση εργασίες γουρούνι με HDInsight με καμπύλη."
   services="hdinsight"
   documentationCenter=""
   authors="Blackmist"
   manager="jhubbard"
   editor="cgronlun"
    tags="azure-portal"/>

<tags
   ms.service="hdinsight"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="big-data"
   ms.date="09/07/2016"
   ms.author="larryfr"/>

#<a name="run-hive-queries-with-hadoop-in-hdinsight-with-curl"></a>Εκτέλεση ερωτημάτων Hive με Hadoop σε HDInsight με καμπύλη

[AZURE.INCLUDE [hive-selector](../../includes/hdinsight-selector-use-hive.md)]

Σε αυτό το έγγραφο, θα μάθετε πώς να χρησιμοποιείτε καμπύλη για εκτέλεση ερωτημάτων Hive σε Hadoop σε σύμπλεγμα Azure HDInsight.

Καμπύλη χρησιμοποιείται για να δείχνουν πώς μπορείτε να αλληλεπιδράσετε με HDInsight με χρήση ανεπεξέργαστα αιτήσεις HTTP για εκτέλεση, παρακολούθηση και ανάκτησης των αποτελεσμάτων Hive ερωτημάτων. Αυτό λειτουργεί, χρησιμοποιώντας το WebHCat REST API (παλαιότερα γνωστό ως Templeton) που παρέχεται από το σύμπλεγμά σας HDInsight.

> [AZURE.NOTE] Εάν είστε ήδη εξοικειωμένοι με τη χρήση των διακομιστών βάσει Linux Hadoop, αλλά είστε εξοικειωμένοι με το HDInsight, ανατρέξτε στο θέμα [Τι πρέπει να γνωρίζετε σχετικά με την Hadoop στην βάσει Linux HDInsight](hdinsight-hadoop-linux-information.md).

##<a id="prereq"></a>Προαπαιτούμενα στοιχεία

Για να ολοκληρώσετε τα βήματα σε αυτό το άρθρο, θα χρειαστείτε τα εξής:

* Hadoop σε σύμπλεγμα HDInsight (Linux ή βασίζεται στα Windows)

* [Καμπύλη](http://curl.haxx.se/)

* [jq](http://stedolan.github.io/jq/)

##<a id="curl"></a>Εκτέλεση ερωτημάτων Hive χρησιμοποιώντας καμπύλη

> [AZURE.NOTE] Όταν χρησιμοποιείτε καμπύλη ή οποιοδήποτε άλλο ΥΠΌΛΟΙΠΟ επικοινωνίας με WebHCat, πρέπει να τον έλεγχο ταυτότητας των αιτήσεων, παρέχοντας το όνομα χρήστη και τον κωδικό πρόσβασης για τη Διαχείριση συμπλέγματος HDInsight. Μπορείτε, επίσης, πρέπει να χρησιμοποιήσετε το όνομα του συμπλέγματος ως μέρος της το ενιαίο αναγνωριστικό πόρου (URI) χρησιμοποιείται για την αποστολή των αιτήσεων στο διακομιστή.
>
> Για τις εντολές σε αυτήν την ενότητα, αντικαταστήστε το **όνομα ΧΡΉΣΤΗ** με το χρήστη για τον έλεγχο ταυτότητας στο σύμπλεγμα και αντικαταστήστε **τον κωδικό ΠΡΌΣΒΑΣΗΣ** με τον κωδικό πρόσβασης για το λογαριασμό χρήστη. Αντικαταστήστε **CLUSTERNAME** με το όνομα του συμπλέγματος.
>
> Το REST API προστατεύεται μέσω [βασικό έλεγχο ταυτότητας](http://en.wikipedia.org/wiki/Basic_access_authentication). Θα πρέπει να κάνετε πάντα αιτήσεις με τη χρήση ασφαλούς HTTP (HTTPS) για να εξασφαλίσετε ότι τα διαπιστευτήριά σας αποστέλλονται με ασφάλεια στο διακομιστή.

1. Από τη γραμμή εντολών, χρησιμοποιήστε την ακόλουθη εντολή για να επιβεβαιώσετε ότι μπορείτε να συνδεθείτε με το σύμπλεγμά σας HDInsight:

        curl -u USERNAME:PASSWORD -G https://CLUSTERNAME.azurehdinsight.net/templeton/v1/status

    Θα πρέπει να λαμβάνετε μια απάντηση παρόμοια με τα εξής:

        {"status":"ok","version":"v1"}

    Οι παράμετροι χρησιμοποιούνται σε αυτήν την εντολή είναι ως εξής:

    * **-u** - το όνομα χρήστη και κωδικό πρόσβασης που χρησιμοποιείται για τον έλεγχο ταυτότητας της αίτησης.
    * **-G** - υποδεικνύει ότι αυτό είναι ένα αίτημα GET.

    Αρχή της διεύθυνσης URL, **https://CLUSTERNAME.azurehdinsight.net/templeton/v1**, θα είναι το ίδιο για όλες τις αιτήσεις. Τη διαδρομή, **/status/status**, υποδεικνύει ότι η αίτηση είναι για να επιστρέψετε σε κατάσταση WebHCat (γνωστό και ως Templeton) για το διακομιστή. Μπορείτε επίσης να ζητήσετε την έκδοση της ομάδας, χρησιμοποιώντας την ακόλουθη εντολή:

        curl -u USERNAME:PASSWORD -G https://CLUSTERNAME.azurehdinsight.net/templeton/v1/version/hive

    Αυτό πρέπει να επιστρέψει μια απάντηση παρόμοια με τα εξής:

        {"module":"hive","version":"0.13.0.2.1.6.0-2103"}

2. Χρησιμοποιήστε τα ακόλουθα για να δημιουργήσετε έναν νέο πίνακα με το όνομα **log4jLogs**:

        curl -u USERNAME:PASSWORD -d user.name=USERNAME -d execute="set+hive.execution.engine=tez;DROP+TABLE+log4jLogs;CREATE+EXTERNAL+TABLE+log4jLogs(t1+string,t2+string,t3+string,t4+string,t5+string,t6+string,t7+string)+ROW+FORMAT+DELIMITED+FIELDS+TERMINATED+BY+' '+STORED+AS+TEXTFILE+LOCATION+'wasbs:///example/data/';SELECT+t4+AS+sev,COUNT(*)+AS+count+FROM+log4jLogs+WHERE+t4+=+'[ERROR]'+AND+INPUT__FILE__NAME+LIKE+'%25.log'+GROUP+BY+t4;" -d statusdir="wasbs:///example/curl" https://CLUSTERNAME.azurehdinsight.net/templeton/v1/hive

    Οι παράμετροι χρησιμοποιούνται σε αυτήν την εντολή είναι ως εξής:

    * **-d** - εφόσον `-G` δεν χρησιμοποιείται, την αίτηση προεπιλογών για τη μέθοδο POST. `-d`Καθορίζει τις τιμές των δεδομένων που έχουν αποσταλεί με την αίτηση.

        * **user.name** - ο χρήστης που εκτελεί την εντολή.

        * **Εκτέλεση** - το HiveQL δηλώσεις για την εκτέλεση.

        * **statusdir** - τον κατάλογο που θα εγγραφούν την κατάσταση για αυτό το έργο.

    Αυτές τις προτάσεις, εκτελέστε τις ακόλουθες ενέργειες:

    * **ΑΠΌΘΕΣΗ ΠΊΝΑΚΑ** - διαγράφει τον πίνακα και το αρχείο δεδομένων, εάν ο πίνακας υπάρχει ήδη.

    * **ΔΗΜΙΟΥΡΓΊΑ ΠΊΝΑΚΑ ΕΞΩΤΕΡΙΚΏΝ** - δημιουργεί ένα νέο πίνακα 'εξωτερικό' στην ομάδα. Εξωτερικοί πίνακες αποθηκεύουν μόνο τον ορισμό του πίνακα, στην ομάδα. Τα δεδομένα είναι προς τα αριστερά στην αρχική τους θέση.

        > [AZURE.NOTE] Εξωτερικοί πίνακες πρέπει να χρησιμοποιείται όταν αναμένετε τα υποκείμενα δεδομένα για να ενημερωθούν από μια εξωτερική προέλευση, όπως μια διεργασία αποστολής αυτοματοποιημένη δεδομένων ή με μια άλλη MapReduce λειτουργία, αλλά θέλετε πάντα Hive ερωτημάτων για να χρησιμοποιήσετε τα πιο πρόσφατα δεδομένα.
        >
        > Απόθεση έναν εξωτερικό πίνακα κάνει **διαγράφει τα δεδομένα, μόνο τον ορισμό του πίνακα** .

    * **ΜΟΡΦΟΠΟΊΗΣΗ ΓΡΑΜΜΉΣ** - την ομάδα σας ενημερώνει για τον τρόπο μορφοποίησης των δεδομένων. Σε αυτήν την περίπτωση, τα πεδία σε κάθε αρχείο καταγραφής διαχωρίζονται από ένα διάστημα.

    * **ΑΠΟΘΗΚΕΥΜΈΝΑ ΩΣ TEXTFILE ΘΈΣΗ** - ενημερώνει Hive όπου τα δεδομένα που είναι αποθηκευμένη (τον κατάλογο/δεδομένα του παραδείγματος) και να έχει αποθηκευτεί ως κείμενο.

    * **ΕΠΙΛΈΞΤΕ** - επιλέγει μια μέτρηση όλων των γραμμών όπου στήλη **Τ4** περιέχει την τιμή **[ΣΦΆΛΜΑΤΟΣ]**. Αυτό πρέπει να επιστρέψει μια τιμή **3** καθώς υπάρχουν τρεις γραμμές που περιέχουν αυτήν την τιμή.

    > [AZURE.NOTE] Παρατηρήστε ότι τα διαστήματα μεταξύ των καταστάσεων HiveQL αντικαθίστανται από το `+` χαρακτήρας όταν χρησιμοποιείται με καμπύλη. Εισαγωγικά τιμές που περιέχει κενό διάστημα, όπως ο οριοθέτης, δεν θα πρέπει να αντικατασταθεί με `+`.

    * **INPUT__FILE__NAME ΌΠΩΣ '% 25.log'** - αυτή η αναζήτηση μόνο για να χρησιμοποιήσετε τα αρχεία που τελειώνουν σε όρια. καταγραφής. Εάν δεν υπάρχει, ομάδα θα επιχειρήσει να πραγματοποιήσετε αναζήτηση σε όλα τα αρχεία σε αυτόν τον κατάλογο και οι υποκατάλογοι, συμπεριλαμβανομένων των αρχείων που δεν ταιριάζουν με τη διάταξη στηλών που ορίζονται για αυτόν τον πίνακα.

    > [AZURE.NOTE] Σημειώστε ότι το 25% είναι η διεύθυνση URL κωδικοποιημένη φόρμας %, ώστε να είναι η πραγματική συνθήκη `like '%.log'`. Το % έχει κωδικοποιηθεί ως διεύθυνση URL, όπως εκλαμβάνεται ως έναν ειδικό χαρακτήρα στις διευθύνσεις URL.

    Αυτή η εντολή πρέπει να επιστρέφει το Αναγνωριστικό εργασίας που μπορούν να χρησιμοποιηθούν για να ελέγξετε την κατάσταση της εργασίας.

        {"id":"job_1415651640909_0026"}

3. Για να ελέγξετε την κατάσταση της εργασίας, χρησιμοποιήστε την ακόλουθη εντολή. Αντικαταστήστε **JOBID** με την τιμή που επιστρέφεται στο προηγούμενο βήμα. Για παράδειγμα, εάν η τιμή επιστροφής ήταν `{"id":"job_1415651640909_0026"}`, στη συνέχεια, θα ήταν **JOBID** `job_1415651640909_0026`.

        curl -G -u USERNAME:PASSWORD -d user.name=USERNAME https://CLUSTERNAME.azurehdinsight.net/templeton/v1/jobs/JOBID | jq .status.state

    Εάν η εργασία έχει ολοκληρωθεί, η κατάσταση θα **ολοκληρώθηκε με**.

    > [AZURE.NOTE] Αυτή η αίτηση καμπύλη επιστρέφει ένα έγγραφο σημειογραφίας αντικειμένων JavaScript (JSON) με πληροφορίες σχετικά με την εργασία; jq χρησιμοποιείται για να ανακτήσετε μόνο την τιμή κατάσταση.

4. Όταν η κατάσταση της εργασίας έχει αλλάξει **ολοκληρώθηκε με**, μπορείτε να ανακτήσετε τα αποτελέσματα της εργασίας από το χώρο αποθήκευσης αντικειμένων Blob του Azure. Το `statusdir` παράμετρος που μεταβιβάστηκε με το ερώτημα περιέχει στη θέση του το αρχείο εξόδου. σε αυτήν την περίπτωση, **wasbs: / / / παράδειγμα/καμπύλη**. Αυτή η διεύθυνση αποθηκεύει το αποτέλεσμα του έργου στον κατάλογο **παράδειγμα/καμπύλη** το προεπιλεγμένο κοντέινερ χώρου αποθήκευσης που χρησιμοποιείται από το σύμπλεγμά σας HDInsight.

    Μπορείτε να λίστα και να κάνετε λήψη αυτών των αρχείων, χρησιμοποιώντας το [Azure CLI](../xplat-cli-install.md). Για παράδειγμα, σε λίστα αρχεία στο **παράδειγμα/καμπύλη**, χρησιμοποιήστε την ακόλουθη εντολή:

        azure storage blob list <container-name> example/curl

    Για να κάνετε λήψη ενός αρχείου, χρησιμοποιήστε τα εξής:

        azure storage blob download <container-name> <blob-name> <destination-file>

    > [AZURE.NOTE] Είτε πρέπει να καθορίσετε το όνομα του λογαριασμού χώρου αποθήκευσης που περιέχει το αντικείμενο blob, χρησιμοποιώντας το `-a` και `-k` παράμετροι ή ρύθμιση του **AZURE\_χώρου ΑΠΟΘΉΚΕΥΣΗΣ\_ΛΟΓΑΡΙΑΣΜΟΎ** και **AZURE\_χώρου ΑΠΟΘΉΚΕΥΣΗΣ\_ACCESS\_αριθμού-ΚΛΕΙΔΙΟΎ** μεταβλητές περιβάλλοντος. Ανατρέξτε στην ενότητα < ένα href = προορισμού "hdinsight-αποστολή-data.md" = "_blank" για περισσότερες πληροφορίες.

6. Χρησιμοποιήστε τις παρακάτω προτάσεις για να δημιουργήσετε έναν νέο πίνακα 'εσωτερικού' με το όνομα **errorLogs**:

        curl -u USERNAME:PASSWORD -d user.name=USERNAME -d execute="set+hive.execution.engine=tez;CREATE+TABLE+IF+NOT+EXISTS+errorLogs(t1+string,t2+string,t3+string,t4+string,t5+string,t6+string,t7+string)+STORED+AS+ORC;INSERT+OVERWRITE+TABLE+errorLogs+SELECT+t1,t2,t3,t4,t5,t6,t7+FROM+log4jLogs+WHERE+t4+=+'[ERROR]'+AND+INPUT__FILE__NAME+LIKE+'%25.log';SELECT+*+from+errorLogs;" -d statusdir="wasbs:///example/curl" https://CLUSTERNAME.azurehdinsight.net/templeton/v1/hive

    Αυτές τις προτάσεις, εκτελέστε τις ακόλουθες ενέργειες:

    * **ΔΗΜΙΟΥΡΓΊΑ ΠΊΝΑΚΑΣ IF δεν ΥΠΆΡΧΕΙ** - δημιουργεί έναν πίνακα, εάν δεν υπάρχει ήδη. Εφόσον δεν χρησιμοποιείται το **ΕΞΩΤΕΡΙΚΌ** λέξεων-κλειδιών, αυτή είναι μια εσωτερική πίνακα, το οποίο είναι αποθηκευμένο στην ομάδα αποθήκη δεδομένων και γίνεται εντελώς από ομάδα.

        > [AZURE.NOTE] Σε αντίθεση με εξωτερική πίνακες, απόθεση ενός πίνακα του εσωτερικού θα διαγράψει καθώς και τα υποκείμενα δεδομένα.

    * **ΑΠΟΘΗΚΕΥΜΈΝΑ ΩΣ ORC** - αποθηκεύει τα δεδομένα σε μορφή βελτιστοποιημένη σε στήλες γραμμής (ORC). Αυτή είναι μια μορφή ιδιαίτερα βελτιστοποιημένη και αποτελεσματική για την αποθήκευση δεδομένων ομάδας.
    * ΑΝΤΙΚΑΤΆΣΤΑΣΗ **Εισαγωγή... ΕΠΙΛΈΞΤΕ** - επιλέγει γραμμές από τον πίνακα **log4jLogs** που περιέχουν **[ΣΦΆΛΜΑΤΟΣ]**και, στη συνέχεια, εισάγει τα δεδομένα στον πίνακα **errorLogs** .
    * **ΕΠΙΛΈΞΤΕ** - επιλέγει όλες τις γραμμές από τον νέο πίνακα **errorLogs** .

7. Χρησιμοποιήστε το Αναγνωριστικό εργασίας που επιστρέφονται για να ελέγξετε την κατάσταση της εργασίας. Μόλις το ολοκληρώθηκε με επιτυχία, χρησιμοποιήστε Azure CLI για Mac, Linux και Windows όπως περιγράφεται προηγουμένως να κάνετε λήψη και να προβάλετε τα αποτελέσματα. Το αποτέλεσμα θα πρέπει να περιέχουν τρεις γραμμές, τα οποία περιέχουν **[ΣΦΆΛΜΑΤΟΣ]**.


##<a id="summary"></a>Σύνοψη

Όπως φαίνεται σε αυτό το έγγραφο, μπορείτε να χρησιμοποιήσετε μια αίτηση HTTP ανεπεξέργαστο για εκτέλεση, παρακολούθηση και προβολή αποτελεσμάτων του Hive εργασίες στην το σύμπλεγμά σας HDInsight.

Για περισσότερες πληροφορίες σχετικά με το περιβάλλον εργασίας ΥΠΌΛΟΙΠΟ που χρησιμοποιούνται σε αυτό το άρθρο, ανατρέξτε στο άρθρο <a href="https://cwiki.apache.org/confluence/display/Hive/WebHCat+Reference" target="_blank">Αναφορά WebHCat</a>.

##<a id="nextsteps"></a>Επόμενα βήματα

Για γενικές πληροφορίες σχετικά με το HDInsight της ομάδας:

* [Χρήση της ομάδας με Hadoop σε HDInsight](hdinsight-use-hive.md)

Για πληροφορίες σχετικά με άλλους τρόπους μπορείτε να εργαστείτε με Hadoop σε HDInsight:

* [Χρήση γουρούνι με Hadoop σε HDInsight](hdinsight-use-pig.md)

* [Χρήση MapReduce με Hadoop σε HDInsight](hdinsight-use-mapreduce.md)

Εάν χρησιμοποιείτε Tez με ομάδα, δείτε τα ακόλουθα έγγραφα για τον εντοπισμό σφαλμάτων πληροφορίες:

* [Χρήση του περιβάλλοντος εργασίας Χρήστη του Tez σε HDInsight που βασίζεται σε Windows](hdinsight-debug-tez-ui.md)

* [Χρήση της προβολής Ambari Tez σε βάσει Linux HDInsight](hdinsight-debug-ambari-tez-view.md)

[hdinsight-sdk-documentation]: http://msdnstage.redmond.corp.microsoft.com/library/dn479185.aspx

[azure-purchase-options]: http://azure.microsoft.com/pricing/purchase-options/
[azure-member-offers]: http://azure.microsoft.com/pricing/member-offers/
[azure-free-trial]: http://azure.microsoft.com/pricing/free-trial/

[apache-tez]: http://tez.apache.org
[apache-hive]: http://hive.apache.org/
[apache-log4j]: http://en.wikipedia.org/wiki/Log4j
[hive-on-tez-wiki]: https://cwiki.apache.org/confluence/display/Hive/Hive+on+Tez
[import-to-excel]: http://azure.microsoft.com/documentation/articles/hdinsight-connect-excel-power-query/


[hdinsight-use-oozie]: hdinsight-use-oozie.md
[hdinsight-analyze-flight-data]: hdinsight-analyze-flight-delay-data.md




[hdinsight-provision]: hdinsight-provision-clusters.md
[hdinsight-submit-jobs]: hdinsight-submit-hadoop-jobs-programmatically.md
[hdinsight-upload-data]: hdinsight-upload-data.md

[powershell-here-strings]: http://technet.microsoft.com/library/ee692792.aspx


