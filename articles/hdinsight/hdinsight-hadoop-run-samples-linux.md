<properties
    pageTitle="Εκτέλεση Hadoop MapReduce δείγματα στην βάσει Linux HDInsight | Microsoft Azure"
    description="Γρήγορα αποτελέσματα με δείγματα MapReduce με βάσει Linux HDInsight. Χρησιμοποιήστε SSH για να συνδεθείτε με το σύμπλεγμα και, στη συνέχεια, χρησιμοποιήστε την εντολή Hadoop για να εκτελέσετε εργασίες δείγμα."
    services="hdinsight"
    documentationCenter=""
    authors="Blackmist"
    manager="jhubbard"
    editor="cgronlun"
    tags="azure-portal"/>

<tags
    ms.service="hdinsight"
    ms.workload="big-data"
    ms.tgt_pltfrm="na"
    ms.devlang="na"
    ms.topic="article"
    ms.date="09/27/2016"
    ms.author="larryfr"/>




#<a name="run-the-hadoop-samples-in-hdinsight"></a>Εκτελέστε τα δείγματα Hadoop στο HDInsight

[AZURE.INCLUDE [samples-selector](../../includes/hdinsight-run-samples-selector.md)]

Βάσει Linux συμπλεγμάτων HDInsight παρέχουν ένα σύνολο δείγματα MapReduce που μπορούν να χρησιμοποιηθούν για να εξοικειωθείτε με την εκτέλεση Hadoop MapReduce εργασιών. Σε αυτό το έγγραφο, μπορείτε να μάθετε περισσότερα σχετικά με τα διαθέσιμα δείγματα και θα καθοδηγήσουν εκτελείται μερικές από αυτές.

##<a name="prerequisites"></a>Προαπαιτούμενα στοιχεία

- **Συνδρομή του Azure**: ανατρέξτε στο θέμα [λήψη Azure δωρεάν δοκιμαστική έκδοση](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)

- **Σύμπλεγμα A Linux βάσει HDInsight**: ανατρέξτε στο θέμα [Γρήγορα αποτελέσματα με τη χρήση Hadoop με ομάδα στο HDInsight στην Linux](hdinsight-hadoop-linux-tutorial-get-started.md)

- **Μια SSH προγράμματος-πελάτη**: για πληροφορίες σχετικά με τη χρήση SSH με το HDInsight, ανατρέξτε στα ακόλουθα άρθρα:

    - [Χρήση SSH με βάσει Linux Hadoop σε HDInsight από Linux, Unix ή λειτουργικό σύστημα OS X](hdinsight-hadoop-linux-use-ssh-unix.md)

    - [Χρήση SSH με βάσει Linux Hadoop σε HDInsight από το Windows](hdinsight-hadoop-linux-use-ssh-windows.md)

## <a name="the-samples"></a>Τα δείγματα ##

**Θέση**: βρίσκονται τα δείγματα στο σύμπλεγμα HDInsight στο **/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar**

**Περιεχόμενα**: τα ακόλουθα δείγματα περιέχονται σε αυτό το αρχείο:

- **aggregatewordcount**: μια συγκέντρωση βάσει πρόγραμμα αντιστοίχιση/μείωση που καταμετρά τις λέξεις στη εισαγωγής αρχείων
- **aggregatewordhist**: μια συγκέντρωση πρόγραμμα που βασίζεται σε χάρτη/μείωση που υπολογίζει το ιστόγραμμα από τις λέξεις στη εισαγωγής αρχείων
- **bbp**: πρόγραμμα αντιστοίχιση/μείωση που χρησιμοποιεί Bailey-Borwein-Plouffe για τον υπολογισμό ακριβή ψηφία του π
- **dbcount**: μια εργασία παράδειγμα που καταμετρά τα αρχεία καταγραφής προβολή σελίδας που είναι αποθηκευμένα σε μια βάση δεδομένων
- **distbbp**: ένα πρόγραμμα αντιστοίχιση/μείωση που χρησιμοποιεί έναν τύπο BBP τύπου για τον υπολογισμό ακριβή bit του π
- **GREP**: ένα πρόγραμμα αντιστοίχιση/μείωση που καταμετρά τις συμφωνίες από μια regex στην είσοδο
- **συμμετοχή σε**: μια εργασία που εφέ συνδέσμου πάνω από ταξινομημένες, εξίσου διαμερίσματα συνόλων δεδομένων
- **multifilewc**: μια εργασία που καταμετρά τις λέξεις από διάφορα αρχεία
- **pentomino**: χάρτη/μείωση πλακιδίου ωοτοκίας προγράμματος για να βρείτε λύσεις σε προβλήματα pentomino
- **pi**: ένα πρόγραμμα αντιστοίχιση/μείωση που υπολογίζει π χρησιμοποιώντας μια ημιπερίοδο Monte μέθοδο Carlo
- **randomtextwriter**: ένα πρόγραμμα αντιστοίχιση/μείωση που γράφει τυχαία δεδομένων κειμένου ανά κόμβο και 10 GB
- **randomwriter**: ένα πρόγραμμα αντιστοίχιση/μείωση που γράφει τυχαία δεδομένων ανά κόμβο και 10 GB
- **secondarysort**: παράδειγμα καθορίζει μια δευτερεύουσα ταξινόμηση για τη μείωση
- **Ταξινόμηση**: ένα πρόγραμμα αντιστοίχιση/μείωση που ταξινομεί τα δεδομένα από το τυχαίο writer
- **sudoku**: μια sudoku επίλυσης
- **teragen**: Δημιουργία δεδομένων για το terasort
- **terasort**: εκτέλεση του terasort
- **teravalidate**: επαλήθευση των αποτελεσμάτων της terasort
- **wordcount**: ένα πρόγραμμα αντιστοίχιση/μείωση που καταμετρά τις λέξεις στη εισαγωγής αρχείων
- **wordmean**: ένα πρόγραμμα αντιστοίχιση/μείωση που υπολογίζει το μέσο μήκος από τις λέξεις στη εισαγωγής αρχείων
- **wordmedian**: ένα πρόγραμμα αντιστοίχιση/μείωση που υπολογίζει το μήκος median από τις λέξεις στη εισαγωγής αρχείων
- **wordstandarddeviation**: ένα πρόγραμμα αντιστοίχιση/μείωση που υπολογίζει την τυπική απόκλιση του μήκους από τις λέξεις στη εισαγωγής αρχείων

**Πηγαίος κώδικας**: πηγαίος κώδικας για αυτά τα δείγματα περιλαμβάνεται στο σύμπλεγμα HDInsight στο **/usr/hdp/2.2.4.9-1/hadoop/src/hadoop-mapreduce-project/hadoop-mapreduce-examples**

> [AZURE.NOTE] Το `2.2.4.9-1` στη διαδρομή είναι η έκδοση της πλατφόρμας Hortonworks δεδομένων για το σύμπλεγμα HDInsight και μπορεί να αλλάξει καθώς ενημερώνεται HDInsight.

## <a name="how-to-run-the-samples"></a>Πώς μπορείτε να εκτελέσετε τα δείγματα ##

1. Σύνδεση με το HDInsight χρησιμοποιώντας SSH, όπως περιγράφεται στα ακόλουθα άρθρα:

    - [Χρήση SSH με βάσει Linux Hadoop σε HDInsight από Linux, Unix ή λειτουργικό σύστημα OS X](hdinsight-hadoop-linux-use-ssh-unix.md)

    - [Χρήση SSH με βάσει Linux Hadoop σε HDInsight από το Windows](hdinsight-hadoop-linux-use-ssh-windows.md)

2. Από το `username@#######:~$` ερώτηση, χρησιμοποιήστε την παρακάτω εντολή για να παραθέσετε τα δείγματα:

        yarn jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar

    Αυτό δημιουργεί τη λίστα των δειγμάτων από την προηγούμενη ενότητα αυτού του εγγράφου.

3. Χρησιμοποιήστε την παρακάτω εντολή για να λάβετε βοήθεια σχετικά με ένα συγκεκριμένο δείγμα. Σε αυτήν την περίπτωση, το δείγμα **wordcount** :

        yarn jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar wordcount

    Θα πρέπει να λαμβάνετε το ακόλουθο μήνυμα:

        Usage: wordcount <in> [<in>...] <out>

    Αυτό υποδεικνύει ότι μπορείτε να παρέχετε πολλές διαδρομές εισαγωγής για τα έγγραφα προέλευσης. Η τελική διαδρομή είναι το σημείο όπου είναι αποθηκευμένο το αποτέλεσμα (καταμέτρηση των λέξεων στα έγγραφα προέλευσης,).

4. Χρησιμοποιήστε τα ακόλουθα για να μετρήσετε όλες τις λέξεις στο τα σημειωματάρια του Leonardo Da Vinci, που παρέχονται ως δείγμα δεδομένων με το σύμπλεγμά σας:

        yarn jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar wordcount /example/data/gutenberg/davinci.txt /example/data/davinciwordcount

    Εισαγωγή δεδομένων για αυτή την εργασία είναι για ανάγνωση από **wasbs:///example/data/gutenberg/davinci.txt**.

    Εξόδου για αυτό το παράδειγμα είναι αποθηκευμένη στο **wasbs: / / / παράδειγμα/δεδομένων/davinciwordcount**.

    > [AZURE.NOTE] Όπως σημειώθηκε στη Βοήθεια για το δείγμα wordcount, μπορείτε να καθορίσετε επίσης πολλά αρχεία εισόδου. Για παράδειγμα, `hadoop jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar wordcount /example/data/gutenberg/davinci.txt /example/data/gutenberg/ulysses.txt /example/data/twowordcount` θα καταμέτρηση λέξεων στο davinci.txt και ulysses.txt.

5. Μόλις ολοκληρωθεί η εργασία, χρησιμοποιήστε την ακόλουθη εντολή για να προβάλετε το αποτέλεσμα:

        hdfs dfs -cat /example/data/davinciwordcount/*

    Αυτό συνδέει όλα τα αρχεία εξόδου που δημιουργήθηκαν με την εργασία και να εμφανίσετε τους. Για αυτό το παράδειγμα βασικές υπάρχει μόνο ένα αρχείο, ωστόσο αν υπάρχουν περισσότερα αυτή η εντολή θα διαδοχικές προσεγγίσεις μέσω όλες τις.

    Το αποτέλεσμα θα είναι παρόμοιο με το εξής:

        zum     1
        zur     1
        zwanzig 1
        zweite  1

    Κάθε γραμμή αντιπροσωπεύει μια λέξη και πόσες φορές Παρουσιάστηκε στα δεδομένα εισόδου.

## <a name="sudoku"></a>Sudoku

Το παράδειγμα Sudoku περιλαμβάνει οδηγίες κάπως μη βοηθητικής χρήσης; "Περιλαμβάνει μια παζλ στη γραμμή εντολών."

[Sudoku](https://en.wikipedia.org/wiki/Sudoku) είναι μια λογική παζλ αποτελείται από τα πλέγματα εννέα 3 x 3. Ορισμένα κελιά στο πλέγμα έχει αριθμούς, ενώ άλλοι είναι κενή και ο στόχος είναι να επιλύσετε για τα κενά κελιά. Η παραπάνω σύνδεση περιλαμβάνει περισσότερες πληροφορίες σχετικά με το Παζλ, αλλά το σκοπό αυτού του δείγματος είναι για την επίλυση για τα κενά κελιά. Επομένως, μας εισαγωγή πρέπει να είναι ένα αρχείο που έχει την παρακάτω μορφή:

- Εννέα γραμμές εννέα στηλών

- Κάθε στήλη μπορεί να περιέχει είτε τον αριθμό ή `?` (το οποίο υποδεικνύει ένα κενό κελί)

- Τα κελιά διαχωρίζονται από ένα διάστημα

Υπάρχει ένα συγκεκριμένο τρόπο για να δημιουργήσετε παζλ Sudoku; Δεν μπορείτε να επαναλάβετε έναν αριθμό σε μια στήλη ή γραμμή. Υπάρχει ένα παράδειγμα σε ένα σύμπλεγμα HDInsight που έχει συνταχθεί σωστά. Το βρίσκεται στην **/usr/hdp/2.2.4.9-1/hadoop/src/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/dancing/puzzle1.dta** και περιέχει τα εξής:

    8 5 ? 3 9 ? ? ? ?
    ? ? 2 ? ? ? ? ? ?
    ? ? 6 ? 1 ? ? ? 2
    ? ? 4 ? ? 3 ? 5 9
    ? ? 8 9 ? 1 4 ? ?
    3 2 ? 4 ? ? 8 ? ?
    9 ? ? ? 8 ? 5 ? ?
    ? ? ? ? ? ? 2 ? ?
    ? ? ? ? 4 5 ? 7 8

> [AZURE.NOTE] Το `2.2.4.9-1` τμήμα της διαδρομής μπορεί να αλλάξει καθώς ενημερώσεις γίνονται στο σύμπλεγμα HDInsight.

Να εκτελέσετε αυτό το παράδειγμα Sudoku, χρησιμοποιήστε την ακόλουθη εντολή:

    yarn jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar sudoku /usr/hdp/2.2.9.1-1/hadoop/src/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/dancing/puzzle1.dta

Τα αποτελέσματα θα πρέπει να είναι παρόμοιο με τα εξής:

    8 5 1 3 9 2 6 4 7
    4 3 2 6 7 8 1 9 5
    7 9 6 5 1 4 3 8 2
    6 1 4 8 2 3 7 5 9
    5 7 8 9 6 1 4 2 3
    3 2 9 4 5 7 8 1 6
    9 4 7 2 8 6 5 3 1
    1 8 5 7 3 9 2 6 4
    2 6 3 1 4 5 9 7 8

## <a name="pi-"></a>PI (π)

Το δείγμα π χρησιμοποιεί μια στατιστική (ημιπεριόδου Monte Carlo) μέθοδο για να εκτιμήσετε την τιμή του π. Σημεία τοποθετείται τυχαία μέσα σε μια μονάδα τετράγωνη επίσης εμπίπτουν σε έναν κύκλο που περιλαμβάνονται σε αυτό το τετράγωνο με πιθανότητα ισούται με την περιοχή του κύκλου, π/4. Την τιμή του π μπορεί να υπολογιστεί από την τιμή του 4R, όπου R είναι η αναλογία της τον αριθμό των σημείων που βρίσκονται μέσα στον κύκλο με τον συνολικό αριθμό των σημείων που βρίσκονται μέσα στο τετράγωνο. Τόσο μεγαλύτερη δείγμα των σημείων χρησιμοποιούνται, τόσο καλύτερες την εκτίμηση είναι.

Το πρόγραμμα αντιστοίχισης για αυτό το δείγμα δημιουργεί έναν αριθμό σημείων τυχαία μέσα σε ένα τετράγωνο μονάδα και, στη συνέχεια, Καταμετρά τον αριθμό των αυτά τα σημεία που βρίσκονται μέσα στον κύκλο.

Το reducer, στη συνέχεια, συγκεντρώνει σημεία μέτρηση από το mappers και υπολογίζει την τιμή του π από το τύπου 4R, όπου R είναι η αναλογία της τον αριθμό των σημείων μέτρηση μέσα στον κύκλο με τον συνολικό αριθμό των σημείων που βρίσκονται μέσα στο τετράγωνο.

Χρησιμοποιήστε την παρακάτω εντολή για να εκτελέσετε αυτό το δείγμα. Αυτό χρησιμοποιεί 16 χάρτες με 10,000,000 δείγματα για να εκτιμήσετε την τιμή του π:

    yarn jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar pi 16 10000000

Η τιμή που επιστρέφεται από αυτό πρέπει να είναι παρόμοια με **3.14159155000000000000**. Για τις αναφορές, τα πρώτα 10 δεκαδικά ψηφία του π είναι 3.1415926535.

##<a name="10gb-greysort"></a>10GB Greysort

GraySort είναι μια ταξινόμηση συγκριτικών των οποίων μετρικό σύστημα είναι το ρυθμό ταξινόμηση (TB/λεπτό) που είναι δυνατό κατά την ταξινόμηση πολύ μεγάλες ποσότητες δεδομένων, συνήθως ένα 100TB ελάχιστο.

Αυτό το δείγμα χρησιμοποιεί έναν μέτρια 10GB δεδομένων έτσι ώστε να εκτελείται σχετικά γρήγορα. Χρησιμοποιεί τις εφαρμογές MapReduce που αναπτύχθηκε από τη Owen O'Malley και Arun Murthy που το ετήσιο συγκριτικών ταξινόμηση terabyte γενικής χρήσης ("daytona") στο 2009 με το ρυθμό 0.578 TB/min (100 TB σε 173 λεπτά). Για περισσότερες πληροφορίες σε αυτό και σε άλλα σημεία αναφοράς ταξινόμησης, ανατρέξτε στην τοποθεσία [Sortbenchmark](http://sortbenchmark.org/) .

Αυτό το δείγμα χρησιμοποιεί τρεις σύνολα MapReduce προγράμματα:

- **TeraGen**: ένα πρόγραμμα MapReduce που δημιουργεί γραμμές δεδομένων για την ταξινόμηση

- **TeraSort**: δείγματα τα δεδομένα εισόδου και χρησιμοποιεί MapReduce για να ταξινομήσετε τα δεδομένα σε ένα σύνολο παραγγελίας

    TeraSort είναι μια βασική ταξινόμηση των συναρτήσεων MapReduce, εκτός από ένα προσαρμοσμένο partitioner που χρησιμοποιεί μια ταξινομημένη λίστα με τα πλήκτρα N-1 δειγματοληψία που ορίζουν την περιοχή κλειδιού για κάθε μείωση. Συγκεκριμένα, όλα τα πλήκτρα αυτών που δείγμα [i-1] < = κλειδί < αποστέλλονται δείγμα [i] για να μειώσετε i. Αυτό εγγυήσεις ότι τα προϊόντα των μείωση i όλα είναι μικρότερη από την έξοδο μείωση i + 1.

- **TeraValidate**: ένα πρόγραμμα MapReduce που επαληθεύει ότι το αποτέλεσμα έχει ταξινομηθεί καθολικά

    Δημιουργεί ένα χάρτη ανά αρχείο στον κατάλογο εξόδου και κάθε αντιστοίχιση εξασφαλίζει ότι κάθε κλειδί είναι μικρότερη ή ίση στην προηγούμενη διαφάνεια. Η συνάρτηση χάρτη δημιουργεί επίσης τις εγγραφές από το πρώτο και το τελευταίο πλήκτρα κάθε αρχείου και, η συνάρτηση μείωση εξασφαλίζει ότι το πρώτο πλήκτρο του αρχείου i είναι μεγαλύτερο από το τελευταίο κλειδί του αρχείου i-1. Προβλήματα αναφέρονται ως αποτέλεσμα την μείωση με τα πλήκτρα που είναι εκτός λειτουργίας.

Χρησιμοποιήστε τα ακόλουθα βήματα για τη δημιουργία δεδομένων, ταξινόμηση και, στη συνέχεια, επικυρώστε το αποτέλεσμα:

1. Δημιουργία και 10GB δεδομένων, τα οποία θα είναι αποθηκευμένα στο χώρο αποθήκευσης του συμπλέγματος HDInsight προεπιλογή στο **wasbs: / / / παράδειγμα / / 10GB-ταξινόμηση-εισαγωγής δεδομένων**:

        yarn jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar teragen -Dmapred.map.tasks=50 100000000 /example/data/10GB-sort-input

    Το `-Dmapred.map.tasks` ενημερώνει Hadoop πόσες εργασίες χάρτη για να χρησιμοποιήσετε για αυτό το έργο. Το τελικό δύο παραμέτρους πείτε της εργασίας για να δημιουργήσετε και 10GB αξίζει δεδομένων και να το αποθηκεύσετε στο **wasbs: / / / παράδειγμα / / 10GB-ταξινόμηση-εισαγωγής δεδομένων**.

2. Χρησιμοποιήστε την παρακάτω εντολή για να ταξινομήσετε τα δεδομένα:

        yarn jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar terasort -Dmapred.map.tasks=50 -Dmapred.reduce.tasks=25 /example/data/10GB-sort-input /example/data/10GB-sort-output

    Το `-Dmapred.reduce.tasks` ενημερώνει Hadoop μείωση πόσες εργασίες για να χρησιμοποιήσετε για την εργασία. Το τελικό δύο παραμέτρους είναι απλώς τις θέσεις εισόδου και εξόδου για τα δεδομένα.

3. Χρησιμοποιήστε τα ακόλουθα για να επικυρώσει τα δεδομένα που δημιουργούνται από την ταξινόμηση:

        yarn jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar teravalidate -Dmapred.map.tasks=50 -Dmapred.reduce.tasks=25 /example/data/10GB-sort-output /example/data/10GB-sort-validate

##<a name="next-steps"></a>Επόμενα βήματα ##

Από αυτό το άρθρο, μάθατε πώς μπορείτε να εκτελέσετε τα δείγματα περιλαμβάνεται με το συμπλεγμάτων βάσει Linux HDInsight. Για προγράμματα εκμάθησης σχετικά με τη χρήση γουρούνι, ομάδας και MapReduce με το HDInsight, ανατρέξτε στα ακόλουθα θέματα:

* [Χρήση γουρούνι με Hadoop σε HDInsight][hdinsight-use-pig]
* [Χρήση της ομάδας με Hadoop σε HDInsight][hdinsight-use-hive]
* [Χρήση MapReduce με Hadoop σε HDInsight] [hdinsight-use-mapreduce]



[hdinsight-errors]: hdinsight-debug-jobs.md
[hdinsight-use-mapreduce]: hdinsight-use-mapreduce.md
[hdinsight-sdk-documentation]: https://msdn.microsoft.com/library/azure/dn479185.aspx

[hdinsight-submit-jobs]: hdinsight-submit-hadoop-jobs-programmatically.md
[hdinsight-introduction]: hdinsight-hadoop-introduction.md



[hdinsight-samples]: hdinsight-run-samples.md

[hdinsight-use-hive]: hdinsight-use-hive.md
[hdinsight-use-pig]: hdinsight-use-pig.md
