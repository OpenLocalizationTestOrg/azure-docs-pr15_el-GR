<properties 
    pageTitle="Δημιουργία και προγραμματισμός αγωγούς, ποδηλάτου δραστηριοτήτων στις εργοστασιακές δεδομένων | Microsoft Azure" 
    description="Μάθετε πώς να δημιουργείτε μια διοχέτευση δεδομένα του Azure εργοστασίου δεδομένων για να μετακινήσετε και μετασχηματισμού δεδομένων. Δημιουργία μιας ροής εργασίας που καθορίζεται από δεδομένα για την παραγωγή έτοιμη για να χρησιμοποιήσετε τις πληροφορίες." 
    keywords="διοχέτευση δεδομένων, δεδομένων βάσει ροής εργασίας"
    services="data-factory" 
    documentationCenter="" 
    authors="sharonlo101" 
    manager="jhubbard" 
    editor="monicar"/>

<tags 
    ms.service="data-factory" 
    ms.workload="data-services" 
    ms.tgt_pltfrm="na" 
    ms.devlang="na" 
    ms.topic="article"
    ms.date="09/12/2016" 
    ms.author="shlo"/>

# <a name="pipelines-and-activities-in-azure-data-factory"></a>Αγωγούς και δραστηριοτήτων στις εργοστασιακές Azure δεδομένων
Σε αυτό το άρθρο σάς βοηθά να κατανοήσετε αγωγούς και δραστηριότητες του Azure εργοστασίου δεδομένων και να τις χρησιμοποιήσετε για να δημιουργήσετε ολοκληρωμένες για να βασίζονται σε δεδομένα ροές εργασίας για την κίνηση δεδομένων και επεξεργασίας δεδομένων σενάρια.  

> [AZURE.NOTE] Σε αυτό το άρθρο προϋποθέτει ότι έχουν περάσει μέσω [Εισαγωγή στις εργοστασιακές Azure δεδομένων](data-factory-introduction.md). Εάν δεν έχετε hands-στο-εμπειρία με τη δημιουργία δεδομένων που θα σας βοηθήσουν εργοστάσια, διέρχονται από τη [Δημιουργία του πρώτου εργοστασίου δεδομένων](data-factory-build-your-first-pipeline.md) πρόγραμμα εκμάθησης θα να κατανοήσετε καλύτερα σε αυτό το άρθρο.  

## <a name="what-is-a-data-pipeline"></a>Τι είναι μια διαδικασία δεδομένων;
**Διαδικασία** είναι μια ομαδοποίηση σχετικών λογικά **δραστηριότητες**. Χρησιμοποιείται για την ομάδα δραστηριότητες σε μια μονάδα που εκτελεί μια εργασία. Για να κατανοήσετε καλύτερα αγωγούς, πρέπει να κατανοήσετε πρώτα μια δραστηριότητα. 

## <a name="what-is-an-activity"></a>Τι είναι μια δραστηριότητα;
Δραστηριότητες ορίζουν τις ενέργειες που θα αναλάβουν τα δεδομένα σας. Κάθε δραστηριότητα λαμβάνει κανέναν ή περισσότερους [συνόλων δεδομένων](data-factory-create-datasets.md) ως εισροές και παράγει ένα ή περισσότερα σύνολα δεδομένων ως αποτέλεσμα. 

Για παράδειγμα, μπορείτε να χρησιμοποιήσετε μια δραστηριότητα Αντιγραφή για να οργανώσετε αντιγραφή δεδομένων από χώρο αποθήκευσης μία δεδομένων σε άλλο χώρο αποθήκευσης δεδομένων. Ομοίως, μπορείτε να χρησιμοποιήσετε μια ομάδα HDInsight δραστηριότητα για να εκτελέσετε ένα ερώτημα ομάδας σε ένα σύμπλεγμα Azure HDInsight μετασχηματισμός των δεδομένων σας. Azure εργοστασίου δεδομένων παρέχει ένα ευρύ φάσμα του [μετασχηματισμού δεδομένων](data-factory-data-transformation-activities.md)και δραστηριότητες [κίνηση δεδομένων](data-factory-data-movement-activities.md) . Μπορείτε επίσης να επιλέξετε για να δημιουργήσετε μια προσαρμοσμένη δραστηριότητα .NET για να εκτελέσετε το δικό σας κώδικα. 

## <a name="sample-copy-pipeline"></a>Δείγμα αντίγραφο διοχέτευσης
Στο παρακάτω δείγμα διοχέτευση, υπάρχει μία δραστηριότητα του τύπου **αντίγραφο** στην ενότητα **δραστηριότητες** . Σε αυτό το δείγμα, την [Αντιγραφή δραστηριότητας](data-factory-data-movement-activities.md) αντιγράφει δεδομένα από το χώρο αποθήκευσης αντικειμένων Blob του Azure σε μια βάση δεδομένων Azure SQL. 

    {
      "name": "CopyPipeline",
      "properties": {
        "description": "Copy data from a blob to Azure SQL table",
        "activities": [
          {
            "name": "CopyFromBlobToSQL",
            "type": "Copy",
            "inputs": [
              {
                "name": "InputDataset"
              }
            ],
            "outputs": [
              {
                "name": "OutputDataset"
              }
            ],
            "typeProperties": {
              "source": {
                "type": "BlobSource"
              },
              "sink": {
                "type": "SqlSink",
                "writeBatchSize": 10000,
                "writeBatchTimeout": "60:00:00"
              }
            },
            "Policy": {
              "concurrency": 1,
              "executionPriorityOrder": "NewestFirst",
              "retry": 0,
              "timeout": "01:00:00"
            }
          }
        ],
        "start": "2016-07-12T00:00:00Z",
        "end": "2016-07-13T00:00:00Z"
      }
    } 

Λάβετε υπόψη τα εξής σημεία:

- Στην ενότητα δραστηριότητες, υπάρχει μόνο μία δραστηριότητα του οποίου ο **Τύπος** έχει οριστεί σε **αντίγραφο**.
- Εισαγωγή δεδομένων για τη δραστηριότητα έχει οριστεί σε **InputDataset** και εξόδου για τη δραστηριότητα έχει οριστεί σε **OutputDataset**.
- Στην ενότητα **typeProperties** , **BlobSource** έχει καθοριστεί ως τύπο προέλευσης και **SqlSink** καθορίζεται ως τύπο δέκτη.

Για πλήρη αναλυτικές οδηγίες για τη δημιουργία αυτήν τη διαδικασία, ανατρέξτε στο θέμα [πρόγραμμα εκμάθησης: αντιγράψτε δεδομένα από το χώρο αποθήκευσης αντικειμένων Blob σε βάση δεδομένων SQL](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md). 

## <a name="sample-transformation-pipeline"></a>Δείγμα μετασχηματισμού διοχέτευσης
Στο παρακάτω δείγμα διοχέτευση, υπάρχει μία δραστηριότητα του τύπου **HDInsightHive** στην ενότητα **δραστηριότητες** . Σε αυτό το δείγμα, στην [ομάδα HDInsight δραστηριότητας](data-factory-hive-activity.md) μετατρέπει τα δεδομένα από ένα χώρο αποθήκευσης αντικειμένων Blob του Azure, εκτελώντας το αρχείο δέσμης ενεργειών ομάδας σε ένα σύμπλεγμα Azure HDInsight Hadoop. 

    {
        "name": "TransformPipeline",
        "properties": {
            "description": "My first Azure Data Factory pipeline",
            "activities": [
                {
                    "type": "HDInsightHive",
                    "typeProperties": {
                        "scriptPath": "adfgetstarted/script/partitionweblogs.hql",
                        "scriptLinkedService": "AzureStorageLinkedService",
                        "defines": {
                            "inputtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/inputdata",
                            "partitionedtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/partitioneddata"
                        }
                    },
                    "inputs": [
                        {
                            "name": "AzureBlobInput"
                        }
                    ],
                    "outputs": [
                        {
                            "name": "AzureBlobOutput"
                        }
                    ],
                    "policy": {
                        "concurrency": 1,
                        "retry": 3
                    },
                    "scheduler": {
                        "frequency": "Month",
                        "interval": 1
                    },
                    "name": "RunSampleHiveActivity",
                    "linkedServiceName": "HDInsightOnDemandLinkedService"
                }
            ],
            "start": "2016-04-01T00:00:00Z",
            "end": "2016-04-02T00:00:00Z",
            "isPaused": false
        }
    }

Λάβετε υπόψη τα εξής σημεία: 

- Στην ενότητα δραστηριότητες, υπάρχει μόνο μία δραστηριότητα του οποίου ο **Τύπος** έχει οριστεί σε **HDInsightHive**.
- Το αρχείο δέσμης ενεργειών ομάδας, **partitionweblogs.hql**, αποθηκεύεται στο ο λογαριασμός Azure χώρου αποθήκευσης (που καθορίζεται από το scriptLinkedService, που ονομάζεται **AzureStorageLinkedService**) και στο φάκελο **δέσμης ενεργειών** σε το κοντέινερ **adfgetstarted**.
- Η ενότητα **ορίζει** χρησιμοποιείται για να καθορίσετε τις ρυθμίσεις χρόνου εκτέλεσης που μεταβιβάζονται στη δέσμη ενεργειών hive ως τιμές παραμέτρων Hive (π.χ. ${hiveconf: inputtable}, {hiveconf:partitionedtable} $).

Για πλήρη αναλυτικές οδηγίες για τη δημιουργία αυτήν τη διαδικασία, ανατρέξτε στο θέμα [πρόγραμμα εκμάθησης: δημιουργία του πρώτου διοχέτευσης την επεξεργασία δεδομένων με χρήση σύμπλεγμα Hadoop](data-factory-build-your-first-pipeline.md). 

## <a name="chaining-activities"></a>Αλυσιδωτή δραστηριοτήτων
Εάν έχετε πολλές δραστηριότητες σε μια διαδικασία και αποτέλεσμα μιας δραστηριότητας δεν είναι μια εισαγωγή δεδομένων από μια άλλη δραστηριότητα, οι δραστηριότητες μπορεί να εκτελείται παράλληλα εάν φέτες εισαγωγής δεδομένων για τις δραστηριότητες είστε έτοιμοι. 

Να συνδέετε δύο δραστηριότητες με από το σύνολο δεδομένων εξόδου μία δραστηριότητας ως του συνόλου δεδομένων εισόδου από την άλλη δραστηριότητα. Οι δραστηριότητες που μπορεί να είναι στη διοχέτευση ίδιο ή σε διαφορετικό αγωγούς. Η δεύτερη δραστηριότητα εκτελεί μόνο όταν η το πρώτο ολοκληρωθεί με επιτυχία. 

Για παράδειγμα, λάβετε υπόψη τα παρακάτω πεζών-κεφαλαίων:
 
1.  Διοχέτευση P1 έχει A1 δραστηριότητας που απαιτεί εξωτερικών εισαγωγής dataset D1 και αγροτικά προϊόντα συνόλου δεδομένων **εξόδου** **D2**.
2.  P2 διοχέτευσης έχει A2 δραστηριότητας που απαιτεί **εισαγωγής** από το σύνολο δεδομένων **D2**και παράγει συνόλου δεδομένων εξόδου D3.
 
Σε αυτό το σενάριο, τη δραστηριότητα A1 εκτελείται, όταν είναι διαθέσιμα τα εξωτερικά δεδομένα και τη συχνότητα προγραμματισμένη διαθεσιμότητα φτάσει.  Τη δραστηριότητα A2 εκτελείται κατά τις προγραμματισμένες φέτες από D2 γίνονται διαθέσιμα και είναι καλούν τη συχνότητα προγραμματισμένη διαθεσιμότητα. Εάν υπάρχει ένα σφάλμα σε μία από τις φέτες στο σύνολο δεδομένων D2, A2 δεν εκτελείται για αυτήν τη φέτα μέχρι να είναι διαθέσιμη.

Προβολή διαγράμματος:

![Αλυσιδωτή δραστηριότητες σε δύο αγωγούς](./media/data-factory-create-pipelines/chaining-two-pipelines.png)

Προβολή διαγράμματος με δύο δραστηριότητες στο την ίδια διαδικασία: 

![Αλυσιδωτή δραστηριότητες στη διοχέτευση ίδια](./media/data-factory-create-pipelines/chaining-one-pipeline.png)

Για περισσότερες πληροφορίες, ανατρέξτε στο θέμα [Προγραμματισμός και εκτέλεση](#chaining-activities). 

## <a name="scheduling-and-execution"></a>Προγραμματισμός και εκτέλεσης
Μέχρι στιγμής που έχουν κατανοητή τι είναι αγωγούς και δραστηριότητες. Έχετε επίσης είδατε πώς είναι καθορισμένο και το υψηλού επιπέδου προβολής των δραστηριοτήτων του Azure εργοστασίου δεδομένων. Τώρα ας δούμε πώς να εκτελεστεί. 

Μια διαδικασία είναι ενεργή μόνο μεταξύ την ώρα έναρξης και ώρα λήξης. Να μην εκτελεστεί πριν από την ώρα έναρξης ή μετά την ώρα λήξης. Εάν βρίσκεται σε παύση τη διαδικασία, λάβετε εκτελεστεί δεν ανεξάρτητα από την ώρα έναρξης και λήξης. Για μια διαδικασία για να εκτελέσετε, αυτό θα πρέπει να δεν είναι δυνατή η παύση. Στην πραγματικότητα, δεν είναι η διαδικασία που λαμβάνει εκτελεστεί. Πρόκειται για τις δραστηριότητες στη διοχέτευση που εκτελούνται. Ωστόσο ό, τι το συνολικό όσον αφορά τη διαδικασία. 

Ανατρέξτε στο θέμα [Προγραμματισμός και εκτέλεση](data-factory-scheduling-and-execution.md) για να κατανοήσετε τον τρόπο λειτουργίας προγραμματισμού και της εκτέλεσης του Azure εργοστασίου δεδομένων.

## <a name="create-pipelines"></a>Δημιουργία αγωγούς
Azure εργοστασίου δεδομένων παρέχει διάφορες μηχανισμούς για σύνταξη και την ανάπτυξη αγωγούς (το οποίο με τη σειρά περιέχει μία ή περισσότερες δραστηριότητες σε αυτό). 

### <a name="using-azure-portal"></a>Χρήση του Azure πύλη
Μπορείτε να χρησιμοποιήσετε επεξεργασίας εργοστασίου δεδομένων στην πύλη του Azure για να δημιουργήσετε μια διαδικασία. Ανατρέξτε στο θέμα [Γρήγορα αποτελέσματα με το Azure εργοστασίου δεδομένων (πρόγραμμα επεξεργασίας δεδομένων εργοστασίου)](data-factory-build-your-first-pipeline-using-editor.md) για ένα αναλυτικές οδηγίες για να ολοκληρωμένες. 

### <a name="using-visual-studio"></a>Χρήση του Visual Studio 
Μπορείτε να χρησιμοποιήσετε το Visual Studio για σύνταξη και ανάπτυξη αγωγούς Azure εργοστασίου δεδομένων. Ανατρέξτε στο θέμα [Γρήγορα αποτελέσματα με το Azure εργοστασίου δεδομένων (Visual Studio)](data-factory-build-your-first-pipeline-using-vs.md) για ένα αναλυτικές οδηγίες για να ολοκληρωμένες. 

### <a name="using-azure-powershell"></a>Χρήση του Azure PowerShell
Μπορείτε να χρησιμοποιήσετε το Azure PowerShell για τη δημιουργία αγωγούς στο Azure εργοστασίου δεδομένων. Ας υποθέσουμε, έχετε ορίσει της διοχέτευσης JSON σε ένα αρχείο στο c:\DPWikisample.json. Μπορείτε να αποστείλετε το στην περίοδο λειτουργίας του Azure εργοστασίου δεδομένων, όπως φαίνεται στο ακόλουθο παράδειγμα:

    New-AzureRmDataFactoryPipeline -ResourceGroupName ADF -Name DPWikisample -DataFactoryName wikiADF -File c:\DPWikisample.json

Ανατρέξτε στο θέμα [Γρήγορα αποτελέσματα με το Azure εργοστασίου δεδομένων (Azure PowerShell)](data-factory-build-your-first-pipeline-using-powershell.md) για ένα ολοκληρωμένες για αναλυτικές οδηγίες για τη δημιουργία μιας προέλευσης δεδομένων με μια διαδικασία. 

### <a name="using-net-sdk"></a>Χρήση του .NET SDK
Μπορείτε να δημιουργήσετε και να αναπτύξετε διοχέτευσης μέσω .NET SDK πολύ. Αυτός ο μηχανισμός μπορεί να χρησιμοποιηθεί για τη δημιουργία αγωγούς μέσω προγραμματισμού. Για περισσότερες πληροφορίες, ανατρέξτε στο θέμα [Δημιουργία, διαχείριση, και την παρακολούθηση εργοστάσια δεδομένων μέσω προγραμματισμού](data-factory-create-data-factories-programmatically.md). 


### <a name="using-azure-resource-manager-template"></a>Χρήση προτύπου για τη διαχείριση πόρων Azure
Μπορείτε να δημιουργήσετε και να αναπτύξετε διοχέτευσης χρησιμοποιώντας ένα πρότυπο από διαχειριστή πόρων Azure. Για περισσότερες πληροφορίες, ανατρέξτε στο θέμα [Γρήγορα αποτελέσματα με το Azure εργοστασίου δεδομένων (Azure από διαχειριστή πόρων)](data-factory-build-your-first-pipeline-using-arm.md). 

### <a name="using-rest-api"></a>Χρήση REST API
Μπορείτε να δημιουργήσετε και να υλοποιήσετε διοχέτευσης χρησιμοποιώντας APIs ΥΠΌΛΟΙΠΑ πολύ. Αυτός ο μηχανισμός μπορεί να χρησιμοποιηθεί για τη δημιουργία αγωγούς μέσω προγραμματισμού. Για περισσότερες πληροφορίες, ανατρέξτε στο θέμα [Δημιουργία ή ενημέρωση μιας διοχέτευσης](https://msdn.microsoft.com/library/azure/dn906741.aspx). 


## <a name="monitor-and-manage-pipelines"></a>Παρακολούθηση και διαχείριση αγωγούς  
Όταν έχει αναπτυχθεί μια διαδικασία, μπορείτε να διαχειρίζεστε και να παρακολουθείτε τις αγωγούς, φέτες και εκτελείται. Διαβάστε περισσότερα σχετικά με το εδώ: [Παρακολούθηση και διαχείριση αγωγούς](data-factory-monitor-manage-pipelines.md).


## <a name="pipeline-json"></a>Διοχέτευση JSON   
Επιτρέψτε μας λαμβάνουν μια πιο κοντινή ματιά στην πώς ορίζεται μια διαδικασία σε μορφή JSON. Η δομή γενικής χρήσης για μια διαδικασία έχει ως εξής:

    {
        "name": "PipelineName",
        "properties": 
        {
            "description" : "pipeline description",
            "activities":
            [
    
            ],
            "start": "<start date-time>",
            "end": "<end date-time>"
        }
    }

Ενότητα " **δραστηριότητες** " μπορεί να έχει μία ή περισσότερες δραστηριότητες που ορίζονται από το μέσα σε αυτό. Κάθε δραστηριότητα έχει την εξής δομή ανώτατου επιπέδου:

    {
        "name": "ActivityName",
        "description": "description", 
        "type": "<ActivityType>",
        "inputs":  "[]",
        "outputs":  "[]",
        "linkedServiceName": "MyLinkedService",
        "typeProperties":
        {
    
        },
        "policy":
        {
        }
        "scheduler":
        {
        }
    }

Παρακάτω πίνακα περιγράφουν τις ιδιότητες εντός των ορισμών JSON δραστηριότητας και διαδικασία:

Ετικέτα | Περιγραφή | Απαιτείται
--- | ----------- | --------
Όνομα | Όνομα της δραστηριότητας ή τη διαδικασία. Καθορίστε ένα όνομα που αντιπροσωπεύει την ενέργεια που έχετε ρυθμίσει τη δραστηριότητα ή διοχέτευσης για να το κάνετε<br/><ul><li>Μέγιστος αριθμός χαρακτήρων: 260</li><li>Πρέπει να ξεκινούν με ένα γράμμα αριθμός ή ένας χαρακτήρας υπογράμμισης (_)</li><li>Παρακάτω χαρακτήρες δεν επιτρέπονται: ".", "+", "?", "/", "<",">", "*", "%", "και", ":","\\"</li></ul> | Ναι
Περιγραφή | Κείμενο που περιγράφει τη δραστηριότητα ή διοχέτευσης χρησιμοποιείται το | Ναι
Τύπος | Καθορίζει τον τύπο της δραστηριότητας. Ανατρέξτε στα άρθρα [Δεδομένων κίνηση δραστηριότητες](data-factory-data-movement-activities.md) και οι [Δραστηριότητες μετασχηματισμού δεδομένων](data-factory-data-transformation-activities.md) για διαφορετικούς τύπους δραστηριοτήτων. | Ναι
εισόδων | Εισαγωγής πίνακες που χρησιμοποιούνται από τη δραστηριότητα<br/><br/>έναν πίνακα εισαγωγής<br/>"εισόδων": [{"όνομα": "inputtable1"}],<br/><br/>δύο πίνακες εισαγωγής <br/>"εισόδων": [{"όνομα": "inputtable1"}, {"όνομα": "inputtable2"}], | Ναι
εξόδους | Πίνακες εξόδου που χρησιμοποιούνται από τον πίνακα activity.// ένα αποτέλεσμα<br/>"εξόδους": [{"όνομα": "outputtable1"}],<br/><br/>δύο πίνακες εξόδου<br/>"εξόδους": [{"όνομα": "outputtable1"}, {"όνομα": "outputtable2"}], | Ναι
linkedServiceName | Το όνομα της υπηρεσίας συνδεδεμένων χρησιμοποιούνται από τη δραστηριότητα. <br/><br/>Μια δραστηριότητα μπορεί να απαιτεί να καθορίσετε την υπηρεσία συνδεδεμένων που συνδέεται με το περιβάλλον απαιτείται υπολογισμού. | Ναι για HDInsight δραστηριότητας και Azure μηχανικής εκμάθησης δέσμη βαθμολογίας δραστηριότητας <br/><br/>Όχι για όλους τους άλλους
typeProperties | Ιδιότητες στην ενότητα typeProperties εξαρτώνται από τον τύπο της δραστηριότητας. | Όχι
πολιτική | Πολιτικές που επηρεάζει τη συμπεριφορά χρόνου εκτέλεσης της δραστηριότητας. Εάν δεν έχει καθοριστεί, προεπιλεγμένες πολιτικές που χρησιμοποιούνται. | Όχι
Έναρξη | Ημερομηνία-ώρα έναρξης για τη διαδικασία. Πρέπει να είναι σε [μορφή ISO](http://en.wikipedia.org/wiki/ISO_8601). Για παράδειγμα: 2014-10-14T16:32:41Z. <br/><br/>Είναι δυνατό να καθορίσετε μια τοπική ώρα, για παράδειγμα μια ώρα Ανατολική ΏΡΑ. Ακολουθεί ένα παράδειγμα: "2016-02-27T06:00:00**-05: 00**", που είναι εκτιμώμενη 6 π.μ.<br/><br/>Οι ιδιότητες έναρξης και λήξης καθορίσετε μαζί ενεργή περίοδο για τη διαδικασία. Αποτέλεσμα φέτες παράγονται μόνο με το ενεργό διάρκεια αυτής της περιόδου. | Όχι<br/><br/>Εάν καθορίσετε μια τιμή για την ιδιότητα τέλος, πρέπει να καθορίσετε τιμή για την ιδιότητα έναρξης.<br/><br/>Την ώρα έναρξης και λήξης μπορεί να και τα δύο είναι κενό για να δημιουργήσετε μια διαδικασία. Πρέπει να καθορίσετε και οι δύο τιμές για να ορίσετε μια ενεργή περίοδο για τη διαδικασία για να εκτελέσετε. Εάν δεν καθορίσετε ώρες έναρξης και λήξης όταν δημιουργείτε μια διαδικασία, μπορείτε να ορίσετε τους χρησιμοποιώντας το cmdlet Set-AzureRmDataFactoryPipelineActivePeriod αργότερα.
Τέλος | Ημερομηνία-ώρα λήξης για τη διαδικασία. Εάν καθορίζεται πρέπει να είναι σε μορφή ISO. Για παράδειγμα: 2014-10-14T17:32:41Z <br/><br/>Είναι δυνατή για να καθορίσετε μια τοπική ώρα, για παράδειγμα ένα Εκτιμώμενη διάρκεια. Ακολουθεί ένα παράδειγμα: "2016-02-27T06:00:00**-05: 00**", που είναι εκτιμώμενη 6 π.μ.<br/><br/>Για να εκτελέσετε τη διαδικασία απεριόριστο χρονικό διάστημα, καθορίστε 9999-09-09 ως η τιμή για την ιδιότητα τέλος. | Όχι <br/><br/>Εάν καθορίσετε μια τιμή για την ιδιότητα έναρξης, πρέπει να καθορίσετε τιμή για την ιδιότητα τέλος.<br/><br/>Ανατρέξτε στις σημειώσεις για την ιδιότητα **Έναρξη** .
isPaused | Εάν οριστεί στην τιμή true τη διαδικασία δεν εκτελείται. Προεπιλεγμένη τιμή = false. Μπορείτε να χρησιμοποιήσετε αυτήν την ιδιότητα για να ενεργοποιήσετε ή να απενεργοποιήσετε. | Όχι 
χρονοδιάγραμμα | η ιδιότητα "Χρονοδιάγραμμα" χρησιμοποιείται για να ορίσετε την επιθυμητή προγραμματισμού για τη δραστηριότητα. Τις δευτερεύουσες ιδιότητές είναι ίδια με αυτά στην [ιδιότητα διαθεσιμότητας σε ένα σύνολο δεδομένων](data-factory-create-datasets.md#Availability). | Όχι |   
| pipelineMode | Η μέθοδος για τον προγραμματισμό εκτελεί για τη διαδικασία. Επιτρέπονται τιμές είναι: προγραμματισμένη (προεπιλογή), ενημερώσεις.<br/><br/>'Προγραμματισμένη' δηλώνει ότι η διαδικασία εκτελείται σε καθορισμένο χρονικό διάστημα σύμφωνα με την ενεργή περίοδο (ώρα έναρξης και λήξης). 'Ενημερώσεις' δηλώνει ότι η διαδικασία εκτελείται μόνο μία φορά. Ενημερώσεις αγωγών που μόλις δημιουργήσατε δεν μπορεί να τροποποιηθεί/ενημέρωση αυτήν τη στιγμή. Για λεπτομέρειες σχετικά με τη ρύθμιση ενημερώσεις, ανατρέξτε στο θέμα [Onetime διοχέτευσης](data-factory-scheduling-and-execution.md#onetime-pipeline) . | Όχι | 
| expirationTime | Διάρκεια του χρόνου μετά τη δημιουργία της για την οποία της διοχέτευσης είναι έγκυρη και πρέπει να παραμείνουν προμήθεια του φακέλου. Εάν δεν έχει ενεργό, απέτυχε, ή σε εκκρεμότητα εκτελείται, της διοχέτευσης διαγράφονται αυτόματα μόλις φτάσει η ώρα λήξης. | Όχι | 
| σύνολα δεδομένων | Λίστα των συνόλων δεδομένων που θα χρησιμοποιηθεί από δραστηριότητες που ορίζονται στη διοχέτευση. Αυτή η ιδιότητα μπορεί να χρησιμοποιηθεί για να ορίσετε σύνολα δεδομένων που σχετίζονται με αυτήν τη διαδικασία και δεν έχει οριστεί σε την προέλευση δεδομένων. Σύνολα δεδομένων που ορίζονται από το μέσα σε αυτήν τη διαδικασία μπορεί να χρησιμοποιηθεί μόνο από αυτήν τη διαδικασία και δεν είναι δυνατή η κοινή χρήση. Για λεπτομέρειες, ανατρέξτε στο θέμα [εύρος συνόλων δεδομένων](data-factory-create-datasets.md#scoped-datasets) .| Όχι |  
 

### <a name="policies"></a>Πολιτικές
Πολιτικές επηρεάζει τη συμπεριφορά χρόνου εκτέλεσης μιας δραστηριότητας, ειδικά όταν γίνεται επεξεργασία στη φέτα ενός πίνακα. Ο παρακάτω πίνακας παρέχει τις λεπτομέρειες.

Ιδιότητα | Επιτρεπόμενες τιμές | Προεπιλεγμένη τιμή | Περιγραφή
-------- | ----------- | -------------- | ---------------
ταυτόχρονης εκτέλεσης | Ακέραιος αριθμός <br/><br/>Μέγιστη τιμή: 10 | 1 | Αριθμός ταυτόχρονης εκτελέσεις της δραστηριότητας.<br/><br/>Καθορίζει τον αριθμό των εκτελέσεις παράλληλες δραστηριότητες που μπορεί να συμβεί σε διαφορετική φέτες. Για παράδειγμα, εάν μια δραστηριότητα πρέπει να ακολουθήσετε ένα μεγάλο σύνολο των διαθέσιμων στοιχείων, χρειάζεται μια μεγαλύτερη τιμή ταυτόχρονης εκτέλεσης επιταχύνει την επεξεργασία δεδομένων. 
executionPriorityOrder | NewestFirst<br/><br/>OldestFirst | OldestFirst | Καθορίζει την ταξινόμηση των δεδομένων φέτες που επεξεργάζονται.<br/><br/>Για παράδειγμα, εάν έχετε 2 χωρίζει (ένα τέτοιο στο 4 μμ και ένα άλλο στις 5 μ.μ.) και και τα δύο είναι σε εκκρεμότητα εκτέλεσης. Εάν ορίσετε το executionPriorityOrder να είναι NewestFirst, γίνεται επεξεργασία πρώτα στη φέτα στις 5 μ.μ.. Ομοίως Εάν ορίσετε το executionPriorityORder να είναι OldestFIrst, στη συνέχεια, στη φέτα στο 4 μμ υποβάλλεται σε επεξεργασία. 
"Επανάληψη" | Ακέραιος αριθμός<br/><br/>Μέγιστη τιμή μπορεί να είναι 10 | 3 | Αριθμός των επαναλήψεων πριν από την επεξεργασία δεδομένων για τη φέτα έχει επισημανθεί ως αποτυχία. Εκτέλεση δραστηριοτήτων για ένα κομμάτι δεδομένων είναι επαναληφθεί έως και το πλήθος των επαναλήψεων καθορισμένο. Επανάληψη γίνεται όσο το δυνατόν πιο σύντομα μετά την αποτυχία.
Λήξη χρονικού ορίου | Χρονικό διάστημα | 00:00:00 | Λήξη χρονικού ορίου για τη δραστηριότητα. Παράδειγμα: 00:10:00 (προϋποθέτει χρονικό όριο 10 λεπτά)<br/><br/>Εάν μια τιμή δεν έχει καθοριστεί ή είναι 0, το χρονικό όριο είναι απεριόριστο.<br/><br/>Εάν ο χρόνος επεξεργασίας δεδομένων σε ένα κομμάτι υπερβαίνει το χρονικό όριο, την ακύρωση και το σύστημα επιχειρεί να επαναλάβει την επεξεργασία. Ο αριθμός των επαναλήψεων εξαρτάται από την ιδιότητα "Επανάληψη". Όταν λήξει το χρονικό όριο, η κατάσταση έχει οριστεί σε λήξη χρόνου ορίου.
καθυστέρηση | Χρονικό διάστημα | 00:00:00 | Καθορίστε την καθυστέρηση πριν από την επεξεργασία δεδομένων από την εκκίνηση του φέτα.<br/><br/>Την εκτέλεση της δραστηριότητας για ένα κομμάτι δεδομένων είναι αποτελέσματα μετά την καθυστέρηση πέρα από το αναμενόμενο χρόνο εκτέλεσης.<br/><br/>Παράδειγμα: 00:10:00 (προϋποθέτει καθυστέρηση 10 λεπτά)
longRetry | Ακέραιος αριθμός<br/><br/>Μέγιστη τιμή: 10 | 1 | Τον αριθμό των προσπαθειών μεγάλη "Επανάληψη" πριν από την εκτέλεση φέτα απέτυχε.<br/><br/>προσπάθειες longRetry είναι τα διαστήματα από longRetryInterval. Επομένως, εάν πρέπει να καθορίσετε μια ώρα μεταξύ προσπάθειες, χρησιμοποιήστε longRetry. Εάν έχουν καθοριστεί "Επανάληψη" και longRetry, κάθε προσπάθεια longRetry περιλαμβάνει προσπάθειες επανάληψης και τον μέγιστο αριθμό των προσπαθειών είναι "Επανάληψη" * longRetry.<br/><br/>Για παράδειγμα, εάν έχετε τις ακόλουθες ρυθμίσεις στην πολιτική δραστηριότητας:<br/>Επανάληψη: 3<br/>longRetry: 2<br/>longRetryInterval: 01:00:00<br/><br/>Ας υποθέσουμε ότι υπάρχει μόνο μία φέτα να εκτελέσει (κατάστασης είναι σε αναμονή) και την εκτέλεση δραστηριοτήτων αποτυγχάνει κάθε φορά. Αρχικά θα 3 διαδοχικές εκτέλεσης προσπάθειες. Μετά από κάθε προσπάθεια, την κατάσταση φέτα θα ήταν "Επανάληψη". Όταν οι πρώτες 3 προσπάθειες επάνω, την κατάσταση φέτα θα ήταν LongRetry.<br/><br/>Μετά από μια ώρα (δηλαδή, τιμή του longRetryInteval), θα ήταν άλλο σύνολο 3 διαδοχικές εκτέλεσης προσπάθειες. Μετά από αυτό, θα αποτύχει η κατάσταση φέτα και θα εφαρμοστούν χωρίς άλλες προσπάθειες. Ως εκ τούτου συνολικά 6 προσπάθειες έγιναν.<br/><br/>Εάν οποιαδήποτε εκτέλεσης ολοκληρωθεί με επιτυχία, η κατάσταση φέτα θα είναι έτοιμη και χωρίς περισσότερες επαναλήψεις είναι Επιχειρήθηκε.<br/><br/>longRetry μπορεί να χρησιμοποιηθεί σε περιπτώσεις όπου εξαρτώμενα δεδομένων φτάσει στα μη καθορισμένα χρονικά ή το συνολικό περιβάλλον είναι flaky στην περιοχή ποια επεξεργασίας δεδομένων πραγματοποιείται. Σε αυτές τις περιπτώσεις, κάνοντας επαναλήψεις διαδοχικά μπορεί να μην σας βοηθήσουν και αυτή η ενέργεια μετά το διάστημα του χρόνου έχει ως αποτέλεσμα το επιθυμητό αποτέλεσμα.<br/><br/>Προειδοποίηση: δεν έχει οριστεί υψηλές τιμές για longRetry ή longRetryInterval. Συνήθως, υψηλότερες τιμές συνεπάγεται η άλλα θέματα. 
longRetryInterval | Χρονικό διάστημα | 00:00:00 | Την καθυστέρηση μεταξύ των προσπαθειών μεγάλη "Επανάληψη" 


## <a name="next-steps"></a>Επόμενα βήματα

- Κατανόηση [τον προγραμματισμό και την εκτέλεση του Azure εργοστασίου δεδομένων](data-factory-scheduling-and-execution.md).  
- Διαβάστε σχετικά με την [κίνηση δεδομένων](data-factory-data-movement-activities.md) και [δυνατότητες μετασχηματισμού δεδομένων](data-factory-data-transformation-activities.md) στις εργοστασιακές δεδομένων Azure
- Κατανόηση [διαχείρισης και την παρακολούθηση Azure εργοστασίου δεδομένων](data-factory-monitor-manage-pipelines.md).
- [Δημιουργήστε και αναπτύξτε το διοχέτευσης τον κατάλογο](data-factory-build-your-first-pipeline.md). 
