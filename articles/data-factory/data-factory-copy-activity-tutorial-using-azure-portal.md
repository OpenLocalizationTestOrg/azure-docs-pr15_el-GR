<properties 
    pageTitle="Πρόγραμμα εκμάθησης: Δημιουργία μιας διοχέτευσης με αντιγραφή δραστηριότητα με Azure πύλη | Microsoft Azure" 
    description="Σε αυτό το πρόγραμμα εκμάθησης, δημιουργείτε μια διοχέτευση Azure εργοστασίου δεδομένων με μια δραστηριότητα αντίγραφο χρησιμοποιώντας το πρόγραμμα επεξεργασίας εργοστασίου δεδομένων στην πύλη του Azure." 
    services="data-factory" 
    documentationCenter="" 
    authors="spelluru" 
    manager="jhubbard" 
    editor="monicar"/>

<tags 
    ms.service="data-factory" 
    ms.workload="data-services" 
    ms.tgt_pltfrm="na" 
    ms.devlang="na" 
    ms.topic="get-started-article" 
    ms.date="09/16/2016" 
    ms.author="spelluru"/>

# <a name="tutorial-create-a-pipeline-with-copy-activity-using-azure-portal"></a>Πρόγραμμα εκμάθησης: Δημιουργία μιας διοχέτευσης με αντιγραφή δραστηριότητα με Azure πύλη
> [AZURE.SELECTOR]
- [Επισκόπηση και τις προϋποθέσεις](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md)
- [Αντιγραφή οδηγού](data-factory-copy-data-wizard-tutorial.md)
- [Πύλη του Azure](data-factory-copy-activity-tutorial-using-azure-portal.md)
- [Visual Studio](data-factory-copy-activity-tutorial-using-visual-studio.md)
- [PowerShell](data-factory-copy-activity-tutorial-using-powershell.md)
- [Azure προτύπου για τη διαχείριση πόρων](data-factory-copy-activity-tutorial-using-azure-resource-manager-template.md)
- [REST API](data-factory-copy-activity-tutorial-using-rest-api.md)
- [.NET API](data-factory-copy-activity-tutorial-using-dotnet-api.md)



Αυτό το πρόγραμμα εκμάθησης θα μάθετε πώς να δημιουργήσετε και να παρακολουθείτε μια εργοστασίου Azure δεδομένων με την πύλη Azure. Της διοχέτευσης στο η προέλευση δεδομένων χρησιμοποιεί μια δραστηριότητα Αντιγραφή για να αντιγράψετε δεδομένα από το χώρο αποθήκευσης Blob του Azure με βάση δεδομένων SQL Azure.

Ακολουθούν τα βήματα που πρέπει να εκτελέσετε ως μέρος αυτού του προγράμματος εκμάθησης:

Βήμα | Περιγραφή
-----| -----------
[Δημιουργία ενός εργοστασίου Azure δεδομένων](#create-data-factory) | Σε αυτό το βήμα, δημιουργείτε μια εργοστασίου Azure δεδομένων με το όνομα **ADFTutorialDataFactory**.  
[Δημιουργία συνδεδεμένων υπηρεσιών](#create-linked-services) | Σε αυτό το βήμα, δημιουργείτε δύο συνδεδεμένες υπηρεσίες: **AzureStorageLinkedService** και **AzureSqlLinkedService**. <br/><br/>Το AzureStorageLinkedService συνδέει το Azure χώρου αποθήκευσης και AzureSqlLinkedService συνδέει τη βάση δεδομένων Azure SQL με το ADFTutorialDataFactory. Τα δεδομένα εισόδου για τη διαδικασία βρίσκεται σε ένα κοντέινερ αντικειμένων blob των αντικειμένων blob του Azure δεδομένων χώρου αποθήκευσης και εξόδου είναι αποθηκευμένα σε έναν πίνακα στη βάση δεδομένων Azure SQL. Γι ' αυτό, προσθέστε αυτές τις δύο δεδομένων αποθηκεύονται ως συνδεδεμένες υπηρεσίες την προέλευση δεδομένων.      
[Δημιουργία εισόδου και εξόδου συνόλων δεδομένων](#create-datasets) | Στο προηγούμενο βήμα, που δημιουργήσατε συνδεδεμένων υπηρεσιών που αναφέρονται σε χώρους αποθήκευσης δεδομένων που περιέχουν δεδομένα εισόδου/εξόδου. Σε αυτό το βήμα, μπορείτε να ορίσετε δύο συνόλων δεδομένων-- **InputDataset** και **OutputDataset** --που αντιπροσωπεύουν τα δεδομένα εισόδου/εξόδου που είναι αποθηκευμένα στο χώρο αποθήκευσης δεδομένων. <br/><br/>Για το InputDataset, μπορείτε να καθορίσετε το κοντέινερ αντικειμένων blob που περιέχει ένα αντικείμενο blob με τα δεδομένα προέλευσης και για το OutputDataset, μπορείτε να καθορίσετε τον πίνακα SQL που αποθηκεύει τα δεδομένα εξόδου. Μπορείτε επίσης να ορίσετε άλλες ιδιότητες όπως δομή, διαθεσιμότητα και την πολιτική. 
[Δημιουργήστε μια διαδικασία](#create-pipeline) | Σε αυτό το βήμα, δημιουργείτε μια διαδικασία με το όνομα **ADFTutorialPipeline** στο το ADFTutorialDataFactory. <br/><br/>Προσθέστε μια **δραστηριότητα αντίγραφο** της διοχέτευσης που αντίγραφα εισαγωγής δεδομένων από το Azure αντικειμένων blob στον πίνακα του Azure SQL εξόδου. Τη δραστηριότητα αντίγραφο εκτελεί την κυκλοφορία δεδομένων Azure εργοστασίου δεδομένων. Αυτό είναι υποστηρίζεται από μια καθολικά διαθέσιμη υπηρεσία που να αντιγράψετε τα δεδομένα μεταξύ των διαφόρων αποθηκεύει δεδομένα με ασφάλεια, αξιοπιστία και με τον τρόπο. Δείτε το άρθρο [Δραστηριότητες κίνηση δεδομένων](data-factory-data-movement-activities.md) για λεπτομέρειες σχετικά με τη δραστηριότητα αντίγραφο. 
[Οθόνη διοχέτευσης](#monitor-pipeline) | Σε αυτό το βήμα, μπορείτε να παρακολουθείτε φέτες εισόδου και εξόδου πινάκων με χρήση του Azure πύλη.

## <a name="prerequisites"></a>Προαπαιτούμενα στοιχεία 
Ολοκλήρωση τις προϋποθέσεις που αναφέρονται στο άρθρο [Επισκόπηση πρόγραμμα εκμάθησης](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) πριν από την εκτέλεση αυτού του προγράμματος εκμάθησης.

## <a name="create-data-factory"></a>Δημιουργία εργοστασίου δεδομένων
Σε αυτό το βήμα, μπορείτε να χρησιμοποιήσετε την πύλη του Azure για τη δημιουργία ενός εργοστασίου Azure δεδομένων με το όνομα **ADFTutorialDataFactory**.

1.  Μετά την καταγραφή στο [Azure πύλη](https://portal.azure.com/), κάντε κλικ στην επιλογή **Δημιουργία**, επιλέξτε **ευφυΐας + ανάλυσης**και κάντε κλικ στην επιλογή **Προέλευση δεδομένων**. 

    ![Δημιουργία -> DataFactory](./media/data-factory-copy-activity-tutorial-using-azure-portal/NewDataFactoryMenu.png)  

6. Στο blade τη **νέα προέλευση δεδομένων** :
    1. Πληκτρολογήστε **ADFTutorialDataFactory** για το **όνομα**. 
    
        ![Νέα blade εργοστασίου δεδομένων](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-new-data-factory.png)

        Το όνομα του εργοστασίου Azure δεδομένων πρέπει να είναι **μοναδικό καθολικό**. Εάν λάβετε το ακόλουθο σφάλμα, αλλάξτε το όνομα του εργοστασίου δεδομένων (για παράδειγμα, yournameADFTutorialDataFactory) και δοκιμάστε να δημιουργήσετε ξανά. Ανατρέξτε στο θέμα [Factory δεδομένων - κανόνες ονοματοθεσίας](data-factory-naming-rules.md) για τους κανόνες ονοματοθεσίας για αντικείμενα εργοστασίου δεδομένων.
    
            Data factory name “ADFTutorialDataFactory” is not available  
     
        ![Όνομα εργοστασίου δεδομένων δεν είναι διαθέσιμη](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-data-factory-not-available.png)
    2. Επιλέξτε το Azure **συνδρομής**.
    3. Για την ομάδα πόρων, κάντε ένα από τα παρακάτω βήματα:
        1. Επιλέξτε **Χρήση υπάρχουσας**και επιλέξτε μια υπάρχουσα ομάδα πόρων από την αναπτυσσόμενη λίστα. 
        2. Επιλέξτε **Δημιουργία νέου**και πληκτρολογήστε το όνομα μιας ομάδας πόρων.   
    
            Ορισμένα από τα βήματα σε αυτό το πρόγραμμα εκμάθησης λαμβάνεται ως δεδομένο ότι χρησιμοποιείτε το όνομα: **ADFTutorialResourceGroup** για την ομάδα πόρων. Για να μάθετε περισσότερα σχετικά με τις ομάδες πόρων, ανατρέξτε στο θέμα [χρήση των ομάδων πόρων για να διαχειριστείτε τους πόρους σας Azure](../azure-resource-manager/resource-group-overview.md).  
    4. Επιλέξτε τη **θέση** για την προέλευση δεδομένων. Μόνο οι περιοχές που υποστηρίζεται από την υπηρεσία εργοστασίου δεδομένων εμφανίζονται στην αναπτυσσόμενη λίστα.
    5. Επιλέξτε **Καρφίτσωμα στην Startboard**.     
    6. Κάντε κλικ στην επιλογή **Δημιουργία**.

        > [AZURE.IMPORTANT] Για να δημιουργήσετε παρουσίες εργοστασίου δεδομένων, πρέπει να είναι ένα μέλος του ρόλου [Συμβολής εργοστασίου δεδομένων](../active-directory/role-based-access-built-in-roles.md/#data-factory-contributor) σε επίπεδο ομάδας συνδρομή/πόρων.
        >  
        >  Το όνομα του εργοστασίου δεδομένων μπορεί να έχει εγγραφεί ως όνομα DNS στο μέλλον και συνεπώς γίνονται δημόσια ορατά.              
9.  Για να δείτε τα μηνύματα κατάστασης/ειδοποίησης, κάντε κλικ στο εικονίδιο καμπάνας στη γραμμή εργαλείων. 

    ![Μηνύματα ειδοποιήσεων](./media/data-factory-copy-activity-tutorial-using-azure-portal/Notifications.png) 
10. Μετά την ολοκλήρωση της δημιουργίας, βλέπετε το blade **Εργοστασίου δεδομένων** , όπως φαίνεται στην εικόνα.

    ![Αρχική σελίδα εργοστασίου δεδομένων](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-data-factory-home-page.png)

## <a name="create-linked-services"></a>Δημιουργία συνδεδεμένων υπηρεσιών
Συνδεδεμένες υπηρεσίες σύνδεση χώροι αποθήκευσης δεδομένων ή τον υπολογισμό υπηρεσίες σε μια εργοστασίου Azure δεδομένων. Ανατρέξτε στο θέμα [αποθηκεύει τις υποστηριζόμενες δεδομένα](data-factory-data-movement-activities.md##supported-data-stores-and-formats) για όλες τις προελεύσεις και δέκτες που υποστηρίζονται από τη δραστηριότητα αντίγραφο. Δείτε [τον υπολογισμό συνδεδεμένες υπηρεσίες](data-factory-compute-linked-services.md) για τη λίστα των υπηρεσιών υπολογισμού υποστηρίζονται από προέλευση δεδομένων. Σε αυτό το πρόγραμμα εκμάθησης, δεν μπορείτε χρησιμοποιήσετε οποιαδήποτε υπηρεσία υπολογισμού. 

Σε αυτό το βήμα, δημιουργείτε δύο συνδεδεμένες υπηρεσίες: **AzureStorageLinkedService** και **AzureSqlLinkedService**. AzureStorageLinkedService συνδεδεμένες συνδέσεις υπηρεσίας λογαριασμού χώρου αποθήκευσης Azure και AzureSqlLinkedService συνδέεται μια βάση δεδομένων Azure SQL με το **ADFTutorialDataFactory**. Μπορείτε να δημιουργήσετε μια διοχέτευση παρακάτω σε αυτό το πρόγραμμα εκμάθησης που αντιγράφει δεδομένα από ένα κοντέινερ αντικειμένων blob στο AzureStorageLinkedService σε έναν πίνακα SQL σε AzureSqlLinkedService.

### <a name="create-a-linked-service-for-the-azure-storage-account"></a>Δημιουργία συνδεδεμένων υπηρεσίας για το λογαριασμό χώρου αποθήκευσης Azure
1.  Στο blade την **Προέλευση δεδομένων** , κάντε κλικ στην επιλογή **συντάκτη και ανάπτυξη** πλακίδιο στην εκκίνηση του **προγράμματος επεξεργασίας** για την προέλευση δεδομένων.

    ![Σύνταξη και ανάπτυξη των πλακιδίων](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-author-deploy-tile.png) 
5. Στο πρόγραμμα **επεξεργασίας**, κάντε κλικ στο κουμπί **Αποθήκευση νέα δεδομένα** στη γραμμή εργαλείων και επιλέξτε **Azure χώρο αποθήκευσης** από το αναπτυσσόμενο μενού. Θα πρέπει να βλέπετε το πρότυπο JSON για τη δημιουργία μιας υπηρεσίας Azure χώρου αποθήκευσης που συνδέονται στο δεξιό παράθυρο. 

    ![Πρόγραμμα επεξεργασίας νέο κουμπί αποθήκευσης δεδομένων](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-editor-newdatastore-button.png)    
6. Αντικατάσταση `<accountname>` και `<accountkey>` με το όνομα λογαριασμού και τιμές κλειδιού λογαριασμού για το λογαριασμό σας Azure χώρου αποθήκευσης. 

    ![Χώρος αποθήκευσης αντικειμένων Blob JSON επεξεργασίας](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-editor-blob-storage-json.png) 
6. Κάντε κλικ στο κουμπί " **Ανάπτυξη** " στη γραμμή εργαλείων. Τώρα, θα πρέπει να δείτε την ανάπτυξη **AzureStorageLinkedService** στην προβολή δέντρου. 

    ![Ανάπτυξη χώρο αποθήκευσης Blob του προγράμματος επεξεργασίας](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-editor-blob-storage-deploy.png)

> [AZURE.NOTE]
> Για λεπτομέρειες σχετικά με τις ιδιότητες JSON, ανατρέξτε στο θέμα [Μετακίνηση δεδομένων από/προς αντικειμένων Blob του Azure](data-factory-azure-blob-connector.md#azure-storage-linked-service) .

### <a name="create-a-linked-service-for-the-azure-sql-database"></a>Δημιουργία συνδεδεμένων υπηρεσίας για τη βάση δεδομένων SQL Azure
1. Στο πρόγραμμα **Επεξεργασίας εργοστασίου δεδομένων**, κάντε κλικ στο κουμπί **Αποθήκευση νέα δεδομένα** στη γραμμή εργαλείων και επιλέξτε **Βάση δεδομένων SQL Azure** από το αναπτυσσόμενο μενού. Θα πρέπει να βλέπετε το πρότυπο JSON για να δημιουργήσετε την υπηρεσία SQL Azure που συνδέονται στο δεξιό παράθυρο.
2. Αντικατάσταση `<servername>`, `<databasename>`, `<username>@<servername>`, και `<password>` με τα ονόματα των Azure SQL διακομιστή, βάση δεδομένων, λογαριασμού χρήστη, και τον κωδικό πρόσβασης. 
3. Κάντε κλικ στο κουμπί " **Ανάπτυξη** " στη γραμμή εργαλείων για να δημιουργήσετε και να αναπτύξετε το **AzureSqlLinkedService**.
4. Επιβεβαιώστε ότι βλέπετε **AzureSqlLinkedService** στην προβολή δέντρου. 

> [AZURE.NOTE]
> Για λεπτομέρειες σχετικά με τις ιδιότητες JSON, ανατρέξτε στο θέμα [Μετακίνηση δεδομένων από/προς βάση δεδομένων SQL Azure](data-factory-azure-sql-connector.md#azure-sql-linked-service-properties) .

## <a name="create-datasets"></a>Δημιουργία συνόλων δεδομένων
Στο προηγούμενο βήμα, που δημιουργήσατε συνδεδεμένες υπηρεσίες **AzureStorageLinkedService** και **AzureSqlLinkedService** για να συνδέσετε ένα λογαριασμό αποθήκευσης Azure και μια βάση δεδομένων Azure SQL με την προέλευση δεδομένων: **ADFTutorialDataFactory**. Σε αυτό το βήμα, μπορείτε να ορίσετε δύο συνόλων δεδομένων-- **InputDataset** και **OutputDataset** --που αντιπροσωπεύουν τα δεδομένα εισόδου/εξόδου που είναι αποθηκευμένα στο χώρο αποθήκευσης δεδομένων που αναφέρονται, AzureStorageLinkedService και AzureSqlLinkedService αντίστοιχα. Για InputDataset, μπορείτε να καθορίσετε το κοντέινερ αντικειμένων blob που περιέχει ένα αντικείμενο blob με τα δεδομένα προέλευσης και για OutputDataset, μπορείτε να καθορίσετε τον πίνακα SQL που αποθηκεύει τα δεδομένα εξόδου. 

### <a name="create-input-dataset"></a>Δημιουργία συνόλου δεδομένων εισαγωγής 
Σε αυτό το βήμα, δημιουργείτε ένα σύνολο δεδομένων με το όνομα **InputDataset** που οδηγεί σε ένα κοντέινερ αντικειμένων blob στο χώρο αποθήκευσης του Azure που αντιπροσωπεύονται από την υπηρεσία **AzureStorageLinkedService** συνδεδεμένες.

1. Στο πρόγραμμα **επεξεργασίας** για την προέλευση δεδομένων, κάντε κλικ στην επιλογή **... Περισσότερες**, κάντε κλικ στην επιλογή **νέο σύνολο δεδομένων**και κάντε κλικ στην επιλογή **χώρος αποθήκευσης αντικειμένων Blob του Azure** από το αναπτυσσόμενο μενού. 

    ![Νέο μενού συνόλου δεδομένων](./media/data-factory-copy-activity-tutorial-using-azure-portal/new-dataset-menu.png)
2. Αντικαταστήστε JSON στο δεξιό παράθυρο, με το παρακάτω τμήμα κώδικα JSON: 

        {
          "name": "InputDataset",
          "properties": {
            "structure": [
              {
                "name": "FirstName",
                "type": "String"
              },
              {
                "name": "LastName",
                "type": "String"
              }
            ],
            "type": "AzureBlob",
            "linkedServiceName": "AzureStorageLinkedService",
            "typeProperties": {
              "folderPath": "adftutorial/",
              "fileName": "emp.txt",
              "format": {
                "type": "TextFormat",
                "columnDelimiter": ","
              }
            },
            "external": true,
            "availability": {
              "frequency": "Hour",
              "interval": 1
            }
          }
        }
        
     Λάβετε υπόψη τα εξής σημεία: 
    
    - σύνολο δεδομένων **Τύπος** έχει οριστεί σε **AzureBlob**.
    - **linkedServiceName** έχει οριστεί σε **AzureStorageLinkedService**. Δημιουργήσατε αυτήν την υπηρεσία συνδεδεμένο στο βήμα 2.
    - **folderPath** έχει οριστεί στο κοντέινερ **adftutorial** . Μπορείτε επίσης να καθορίσετε το όνομα του ένα blob μέσα στο φάκελο χρησιμοποιώντας την ιδιότητα **fileName** . Εφόσον δεν καθορίζετε το όνομα του το αντικείμενο blob, δεδομένα από όλα τα αντικείμενα blob στο κοντέινερ θεωρείται ως μια εισαγωγής δεδομένων.  
    - μορφοποίηση **τύπου** έχει οριστεί σε **TextFormat**
    - Υπάρχουν δύο πεδία στο αρχείο κειμένου- **όνομα** και **Επώνυμο** – διαχωρίζονται από ένα κόμμα (**Διαχωριστικό_στήλης**) 
    - Η **διαθεσιμότητα** έχει οριστεί σε **ωριαία** (**συχνότητα** έχει οριστεί σε **ώρα** και **διάστημα** έχει οριστεί σε **1**). Επομένως, εργοστασίου δεδομένων αναζητά δεδομένα εισόδου κάθε ώρα στον ριζικό φάκελο του κοντέινερ αντικειμένων blob (**adftutorial**) που καθορίσατε. 
    
    Εάν δεν μπορείτε να καθορίσετε ένα **όνομα αρχείου** για ένα σύνολο δεδομένων **εισόδου** , όλων των αρχείων/BLOB από το φάκελο εισαγωγής (**folderPath**) θεωρούνται ως εισροές. Εάν καθορίσετε ένα όνομα αρχείου στο το JSON, μόνο το καθορισμένο αρχείο/blob θεωρείται asn εισαγωγής.
 
    Εάν δεν καθορίσετε ένα **όνομα αρχείου** για έναν **πίνακα αποτελεσμάτων**, τα αρχεία που δημιουργούνται στο το **folderPath** ονομάζονται με την εξής μορφή: δεδομένων. &lt;Guid\&gt;. txt (παράδειγμα: Data.0a405f8a-93ff-4c6f-b3be-f69616f1df7a.txt.).

    Για να ορίσετε **folderPath** και δυναμικά με βάση την ώρα **SliceStart** **όνομα αρχείου** , χρησιμοποιήστε την ιδιότητα **partitionedBy** . Στο παρακάτω παράδειγμα, folderPath χρησιμοποιεί έτος, μήνα και την ημέρα από την SliceStart (ώρα έναρξης της στη φέτα που υποβάλλεται σε επεξεργασία) και ώρα από την SliceStart χρησιμοποιεί το όνομα αρχείου. Για παράδειγμα, εάν μια φέτα που παράγεται για 2016-09-20T08:00:00, το όνομα φακέλου έχει οριστεί σε wikidatagateway/wikisampledataout/2016/09/20 και το όνομα του αρχείου που έχει οριστεί σε 08.csv. 

            "folderPath": "wikidatagateway/wikisampledataout/{Year}/{Month}/{Day}",
            "fileName": "{Hour}.csv",
            "partitionedBy": 
            [
                { "name": "Year", "value": { "type": "DateTime", "date": "SliceStart", "format": "yyyy" } },
                { "name": "Month", "value": { "type": "DateTime", "date": "SliceStart", "format": "MM" } }, 
                { "name": "Day", "value": { "type": "DateTime", "date": "SliceStart", "format": "dd" } }, 
                { "name": "Hour", "value": { "type": "DateTime", "date": "SliceStart", "format": "hh" } } 
            ],
2. Κάντε κλικ στο κουμπί " **Ανάπτυξη** " στη γραμμή εργαλείων για να δημιουργήσετε και να αναπτύξετε το σύνολο δεδομένων **InputDataset** . Επιβεβαιώστε ότι μπορείτε να δείτε το **InputDataset** στην προβολή δέντρου.

> [AZURE.NOTE]
> Για λεπτομέρειες σχετικά με τις ιδιότητες JSON, ανατρέξτε στο θέμα [Μετακίνηση δεδομένων από/προς αντικειμένων Blob του Azure](data-factory-azure-blob-connector.md#azure-blob-dataset-type-properties) .

### <a name="create-output-dataset"></a>Δημιουργία συνόλου δεδομένων εξόδου
Σε αυτό το τμήμα από το βήμα, δημιουργείτε ένα σύνολο δεδομένων εξόδου που ονομάζεται **OutputDataset**. Σε αυτό το σύνολο δεδομένων οδηγεί σε έναν πίνακα SQL στη βάση δεδομένων Azure SQL που αντιπροσωπεύονται από **AzureSqlLinkedService**. 

1. Στο πρόγραμμα **επεξεργασίας** για την προέλευση δεδομένων, κάντε κλικ στην επιλογή **... Περισσότερες**, κάντε κλικ στην επιλογή **νέο σύνολο δεδομένων**και κάντε κλικ στην επιλογή **Azure SQL** από το αναπτυσσόμενο μενού. 
2. Αντικαταστήστε JSON στο δεξιό παράθυρο, με το παρακάτω τμήμα κώδικα JSON:

        {
          "name": "OutputDataset",
          "properties": {
            "structure": [
              {
                "name": "FirstName",
                "type": "String"
              },
              {
                "name": "LastName",
                "type": "String"
              }
            ],
            "type": "AzureSqlTable",
            "linkedServiceName": "AzureSqlLinkedService",
            "typeProperties": {
              "tableName": "emp"
            },
            "availability": {
              "frequency": "Hour",
              "interval": 1
            }
          }
        }
        
     Λάβετε υπόψη τα εξής σημεία: 
    
    - σύνολο δεδομένων **Τύπος** έχει οριστεί σε **AzureSQLTable**.
    - **linkedServiceName** έχει οριστεί σε **AzureSqlLinkedService** (που δημιουργήσατε αυτήν την υπηρεσία συνδεδεμένο στο βήμα 2).
    - **όνομα πίνακα** έχει οριστεί σε **emp**.
    - Υπάρχουν τρεις στήλες- **Αναγνωριστικό**, **όνομα**και **Επώνυμο** – στον πίνακα emp στη βάση δεδομένων. Αναγνωριστικό είναι μια στήλη, επομένως, πρέπει να καθορίσετε μόνο **όνομα** και **Επώνυμο** εδώ.
    - Η **διαθεσιμότητα** έχει οριστεί σε **ωριαία** (**συχνότητα** ορισμένη σε **ώρα** και **διάστημα** οριστεί σε **1**).  Η υπηρεσία εργοστασίου δεδομένων δημιουργεί μια φέτα δεδομένων εξόδου κάθε ώρα στον πίνακα **emp** στη βάση δεδομένων Azure SQL.

3. Κάντε κλικ στο κουμπί " **Ανάπτυξη** " στη γραμμή εργαλείων για να δημιουργήσετε και να αναπτύξετε το σύνολο δεδομένων **OutputDataset** . Επιβεβαιώστε ότι μπορείτε να δείτε το **OutputDataset** στην προβολή δέντρου. 

> [AZURE.NOTE]
> Για λεπτομέρειες σχετικά με τις ιδιότητες JSON, ανατρέξτε στο θέμα [Μετακίνηση δεδομένων από/προς βάση δεδομένων SQL Azure](data-factory-azure-sql-connector.md#azure-sql-linked-service-properties) .

## <a name="create-pipeline"></a>Δημιουργία διοχέτευσης
Σε αυτό το βήμα, δημιουργείτε μια διαδικασία με μια **Δραστηριότητα αντίγραφο** που χρησιμοποιεί **InputDataset** ως είσοδο και **OutputDataset** ως αποτέλεσμα.

1. Στο πρόγραμμα **επεξεργασίας** για την προέλευση δεδομένων, κάντε κλικ στην επιλογή **... Περισσότερες**, και κάντε κλικ στην επιλογή **νέα διοχέτευσης**. Εναλλακτικά, μπορείτε να κάντε δεξί κλικ **αγωγούς** στην προβολή δέντρου και κάντε κλικ στην επιλογή **νέα διοχέτευσης**.
2. Αντικαταστήστε JSON στο δεξιό παράθυρο, με το παρακάτω τμήμα κώδικα JSON: 
        
        {
          "name": "ADFTutorialPipeline",
          "properties": {
            "description": "Copy data from a blob to Azure SQL table",
            "activities": [
              {
                "name": "CopyFromBlobToSQL",
                "type": "Copy",
                "inputs": [
                  {
                    "name": "InputDataset"
                  }
                ],
                "outputs": [
                  {
                    "name": "OutputDataset"
                  }
                ],
                "typeProperties": {
                  "source": {
                    "type": "BlobSource"
                  },
                  "sink": {
                    "type": "SqlSink",
                    "writeBatchSize": 10000,
                    "writeBatchTimeout": "60:00:00"
                  }
                },
                "Policy": {
                  "concurrency": 1,
                  "executionPriorityOrder": "NewestFirst",
                  "retry": 0,
                  "timeout": "01:00:00"
                }
              }
            ],
            "start": "2016-07-12T00:00:00Z",
            "end": "2016-07-13T00:00:00Z"
          }
        } 

    Λάβετε υπόψη τα εξής σημεία:

    - Στην ενότητα δραστηριότητες, υπάρχει μόνο μία δραστηριότητα του οποίου ο **Τύπος** έχει οριστεί σε **αντίγραφο**.
    - Εισαγωγή δεδομένων για τη δραστηριότητα έχει οριστεί σε **InputDataset** και εξόδου για τη δραστηριότητα έχει οριστεί σε **OutputDataset**.
    - Στην ενότητα **typeProperties** , **BlobSource** έχει καθοριστεί ως τύπο προέλευσης και **SqlSink** καθορίζεται ως τύπο δέκτη.

    Αντικαταστήστε την τιμή της ιδιότητας **Έναρξη** με την τρέχουσα ημέρα και **Τέλος** τιμή με την επόμενη ημέρα. Μπορείτε να καθορίσετε μόνο το τμήμα της ημερομηνίας και να παραλείψετε το τμήμα ώρας από την ημερομηνία ώρα. Για παράδειγμα, "2016-02-03", που είναι ισοδύναμη με "2016-02-03T00:00:00Z"
    
    Και τα δύο έναρξης και λήξης ημερομηνίες-ώρες πρέπει να είναι σε [μορφή ISO](http://en.wikipedia.org/wiki/ISO_8601). Για παράδειγμα: 2016-10-14T16:32:41Z. Την ώρα **λήξης** είναι προαιρετικό, αλλά χρησιμοποιούμε σε αυτό το πρόγραμμα εκμάθησης. 
    
    Εάν δεν καθορίσετε τιμή για την ιδιότητα **Τέλος** , υπολογίζεται ως "**Έναρξη + 48 ώρες**". Για να εκτελέσετε τη διαδικασία απεριόριστο χρονικό διάστημα, καθορίστε **9999-09-09** ως η τιμή για την ιδιότητα **Τέλος** .
    
    Στο προηγούμενο παράδειγμα, υπάρχουν 24 φέτες δεδομένων όπως κάθε φέτα δεδομένων παράγεται ανά ώρα.
    
4. Κάντε κλικ στο κουμπί " **Ανάπτυξη** " στη γραμμή εργαλείων για να δημιουργήσετε και να αναπτύξετε το **ADFTutorialPipeline**. Επιβεβαιώστε ότι μπορείτε να δείτε τη διαδικασία στην προβολή δέντρου. 
5. Τώρα, κλείστε το **πρόγραμμα επεξεργασίας** blade κάνοντας κλικ στο κουμπί **X**. Κάντε κλικ στο **X** ξανά για να δείτε την αρχική σελίδα **Εργοστασίου δεδομένων** για το **ADFTutorialDataFactory**.

**Συγχαρητήρια!** Με επιτυχία έχετε δημιουργήσει μια εργοστασίου Azure δεδομένων, συνδεδεμένες υπηρεσίες, πίνακες και μια διαδικασία και έχει προγραμματιστεί της διοχέτευσης.   
 
### <a name="view-the-data-factory-in-a-diagram-view"></a>Δείτε την προέλευση δεδομένων σε μια προβολή διαγράμματος 
1. Στο blade την **Προέλευση δεδομένων** , κάντε κλικ στην επιλογή **διαγράμματος**.

    ![Blade εργοστασίου δεδομένων - πλακίδιο του διαγράμματος](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-datafactoryblade-diagramtile.png)
2. Θα πρέπει να δείτε το διάγραμμα παρόμοια με την εικόνα που ακολουθεί: 

    ![Προβολή διαγράμματος](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-diagram-blade.png)

    Μπορείτε να κάνετε μεγέθυνση, σμίκρυνση, ζουμ στο 100%, ζουμ για να προσαρμοστεί αυτόματα τοποθετήστε αγωγούς και τους πίνακες και εμφανίζουν πληροφορίες καταγωγής (επισημαίνει στοιχεία νέα και μετάδοση των επιλεγμένων στοιχείων).  Μπορείτε να κάνετε κλικ σε ένα αντικείμενο (πίνακας εισόδου/εξόδου ή διοχέτευσης) για να δείτε τις ιδιότητες για το. 
3. Κάντε δεξί κλικ στην προβολή διαγράμματος **ADFTutorialPipeline** και κάντε κλικ στην επιλογή **Άνοιγμα διοχέτευσης**. 

    ![Άνοιγμα διοχέτευσης](./media/data-factory-copy-activity-tutorial-using-azure-portal/DiagramView-OpenPipeline.png)
4. Θα πρέπει να δείτε τις δραστηριότητες στη διοχέτευση μαζί με σύνολα δεδομένων εισόδου και εξόδου για τις δραστηριότητες. Σε αυτό το πρόγραμμα εκμάθησης, έχετε μόνο μία δραστηριότητα στη διοχέτευση (αντιγραφή δραστηριότητα) με InputDataset ως σύνολο εισαγωγής δεδομένων και OutputDataset ως σύνολο δεδομένων εξόδου.   

    ![Άνοιγμα διοχέτευσης προβολή](./media/data-factory-copy-activity-tutorial-using-azure-portal/DiagramView-OpenedPipeline.png)
5. Κάντε κλικ στην επιλογή **εργοστασίου δεδομένων** στην πορεία στην επάνω αριστερή γωνία για να επιστρέψετε στην προβολή διαγράμματος. Η προβολή διαγράμματος εμφανίζει όλα τα αγωγούς. Σε αυτό το παράδειγμα, έχετε δημιουργήσει μόνο μία διοχέτευσης.   
 

## <a name="monitor-pipeline"></a>Οθόνη διοχέτευσης
Σε αυτό το βήμα, μπορείτε να χρησιμοποιήσετε την πύλη του Azure να παρακολουθείτε τι συμβαίνει στο ενός εργοστασίου Azure δεδομένων. 

### <a name="monitor-pipeline-using-diagram-view"></a>Οθόνη διοχέτευσης χρησιμοποιώντας την προβολή διαγράμματος

1. Κάντε κλικ στο **X** για να κλείσετε την προβολή **διαγράμματος** για να δείτε την αρχική σελίδα εργοστασίου δεδομένων για την προέλευση δεδομένων. Εάν έχετε κλείσει το πρόγραμμα περιήγησης web, κάντε τα εξής βήματα: 
    2. Μεταβείτε στην [πύλη Azure](https://portal.azure.com/). 
    2. Κάντε διπλό κλικ στο **ADFTutorialDataFactory** στην το **Startboard** (ή) κάντε κλικ στην επιλογή **εργοστάσια δεδομένων** από το αριστερό μενού και αναζητήστε το ADFTutorialDataFactory. 
3. Θα πρέπει να βλέπετε το πλήθος και τα ονόματα πινάκων και διοχέτευσης που δημιουργήσατε σε αυτό blade.

    ![αρχική σελίδα με ονόματα](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-datafactory-home-page-pipeline-tables.png)
4. Στη συνέχεια, κάντε κλικ στο πλακίδιο **συνόλων δεδομένων** .
5. Στο blade τα **σύνολα δεδομένων** , κάντε κλικ στην επιλογή **InputDataset**. Σε αυτό το σύνολο δεδομένων είναι του συνόλου δεδομένων εισόδου για **ADFTutorialPipeline**.

    ![Σύνολα δεδομένων με επιλεγμένο InputDataset](./media/data-factory-copy-activity-tutorial-using-azure-portal/DataSetsWithInputDatasetFromBlobSelected.png)   
5. Κάντε κλικ στην επιλογή **... (αποσιωπητικά)** Για να δείτε όλες τις φέτες δεδομένων.

    ![Όλα εισαγωγής δεδομένων φέτες](./media/data-factory-copy-activity-tutorial-using-azure-portal/all-input-slices.png)  

    Παρατηρήσετε ότι όλες τις φέτες δεδομένων έως και την τρέχουσα ώρα είναι **έτοιμη** , επειδή το αρχείο **emp.txt** υπάρχει πάντα στο κοντέινερ αντικειμένων blob: **adftutorial\input**. Επιβεβαιώστε ότι δεν υπάρχει φέτες εμφανίζονται στην ενότητα **πρόσφατα αποτυχίας φέτες** στο κάτω μέρος.

    Λίστες τόσο **ενημερώσει πρόσφατα φέτες** και **πρόσφατα απέτυχε φέτες** ταξινομούνται από την **ΤΕΛΕΥΤΑΊΑ ΕΝΗΜΈΡΩΣΗ ΏΡΑ**. 
    
    Κάντε κλικ στο κουμπί " **φίλτρο** " στη γραμμή εργαλείων για να φιλτράρετε τις φέτες.  
    
    ![Φιλτράρισμα φέτες εισαγωγής](./media/data-factory-copy-activity-tutorial-using-azure-portal/filter-input-slices.png)
6. Κλείστε τις λεπίδες μέχρι να εμφανιστεί το blade **συνόλων δεδομένων** . Κάντε κλικ στην επιλογή το **OutputDataset**. Σε αυτό το σύνολο δεδομένων είναι του συνόλου δεδομένων εξόδου για **ADFTutorialPipeline**.

    ![blade σύνολα δεδομένων](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-datasets-blade.png)
6. Θα πρέπει να βλέπετε το blade **OutputDataset** , όπως φαίνεται στην παρακάτω εικόνα:

    ![blade πίνακα](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-table-blade.png) 
7. Παρατηρήστε ότι έχουν παραχθεί ήδη τις φέτες δεδομένων έως και την τρέχουσα ώρα και είναι **Έτοιμες**. Δεν υπάρχει φέτες εμφανίζεται στην ενότητα **φέτες πρόβλημα** στο κάτω μέρος.
8. Κάντε κλικ στην επιλογή **... (Αποσιωπητικά)** Για να δείτε όλες τις φέτες.

    ![blade φέτες δεδομένων](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-dataslices-blade.png)
9. Κάντε κλικ σε οποιαδήποτε φέτα δεδομένων από τη λίστα και θα πρέπει να βλέπετε το blade **φέτα δεδομένων** .

    ![blade φέτα δεδομένων](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-dataslice-blade.png)
  
    Εάν στη φέτα δεν είναι σε κατάσταση **είστε έτοιμοι** , μπορείτε να δείτε την επόμενη φέτες που δεν είναι έτοιμα και εμποδίζουν την τρέχουσα φέτα από την εκτέλεση στη λίστα **νέα φέτες που είναι δεν είναι έτοιμο** .
11. Στο το blade **ΦΈΤΑ ΔΕΔΟΜΈΝΩΝ** , θα πρέπει να βλέπετε όλες τις δραστηριότητες εκτελείται στη λίστα στο κάτω μέρος. Κάντε κλικ στην επιλογή μιας **δραστηριότητας εκτέλεση** για να δείτε το blade **δραστηριότητας εκτέλεση λεπτομέρειες** . 

    ![Λεπτομέρειες Εκτέλεση δραστηριοτήτων](./media/data-factory-copy-activity-tutorial-using-azure-portal/ActivityRunDetails.png)
12. Κάντε κλικ στο **X** για να κλείσετε όλα τα πτερύγια μέχρι να μπορείτε να επιστρέψετε στην την αρχική blade για το **ADFTutorialDataFactory**.
14. (προαιρετικό) Επιλέξτε **αγωγούς** στην αρχική σελίδα για **ADFTutorialDataFactory**, κάντε κλικ στην επιλογή **ADFTutorialPipeline** στο το blade **αγωγούς** και λεπτομερούς πινάκων (**Consumed**) εισόδου ή εξόδου πίνακες (**που ΠΑΡΑΓΟΝΤΑΙ**).
15. Εκκίνηση του **SQL Server Management Studio**, συνδεθείτε με τη βάση δεδομένων SQL Azure και επιβεβαιώστε ότι οι γραμμές έχουν εισαχθεί στον πίνακα **emp** στη βάση δεδομένων.

    ![αποτελέσματα του ερωτήματος SQL](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-sql-query-results.png)

### <a name="monitor-pipeline-using-monitor--manage-app"></a>Παρακολούθηση της διοχέτευσης με οθόνη & Διαχείριση εφαρμογών
Μπορείτε επίσης να χρησιμοποιείτε οθόνη & Διαχείριση εφαρμογών για την παρακολούθηση της σας αγωγούς. Για λεπτομερείς πληροφορίες σχετικά με τη χρήση αυτής της εφαρμογής, ανατρέξτε στο θέμα [οθόνη και να διαχειριστείτε αγωγούς εργοστασίου δεδομένων Azure χρησιμοποιώντας παρακολούθησης και διαχείρισης εφαρμογών](data-factory-monitor-manage-app.md).

1. Κάντε κλικ στην επιλογή **Παρακολούθηση και διαχείριση** πλακίδιο στην αρχική σελίδα για την προέλευση δεδομένων.

    ![Παρακολούθηση και διαχείριση πλακιδίων](./media/data-factory-copy-activity-tutorial-using-azure-portal/monitor-manage-tile.png) 
2. Θα πρέπει να βλέπετε **την οθόνη και διαχείριση εφαρμογών**. Αλλάξτε την **ώρα έναρξης** και **ώρα λήξης** για να συμπεριλάβετε έναρξης (2016-07 12) και λήξης (2016-07-13) σας αγωγών και κάντε κλικ στο κουμπί **εφαρμογή**. 

    ![Παρακολούθηση και διαχείριση εφαρμογών](./media/data-factory-copy-activity-tutorial-using-azure-portal/monitor-and-manage-app.png) 
3. Επιλέξτε ένα παράθυρο δραστηριότητα στη λίστα των **Windows δραστηριότητας** για να δείτε λεπτομέρειες σχετικά με αυτήν. 
    ![Λεπτομέρειες παραθύρου δραστηριότητα](./media/data-factory-copy-activity-tutorial-using-azure-portal/activity-window-details.png)

## <a name="summary"></a>Σύνοψη 
Σε αυτό το πρόγραμμα εκμάθησης, έχετε δημιουργήσει ένα εργοστασίου Azure δεδομένων για να αντιγράψετε τα δεδομένα από μια Azure αντικειμένων blob σε μια βάση δεδομένων Azure SQL. Χρησιμοποιήσατε την πύλη του Azure για να δημιουργήσετε την προέλευση δεδομένων, συνδεδεμένες υπηρεσίες, σύνολα δεδομένων και μια διαδικασία. Ακολουθούν τα βήματα υψηλού επιπέδου που έχει πραγματοποιηθεί σε αυτό το πρόγραμμα εκμάθησης:  

1.  Δημιουργία μιας Azure **εργοστασίου δεδομένων**.
2.  Δημιουργία **συνδεδεμένων υπηρεσιών**:
    1. Μια υπηρεσία **Αποθήκευσης Azure** συνδεδεμένες για να συνδέσετε το λογαριασμό σας χώρο αποθήκευσης Azure που περιέχει τα δεδομένα εισόδου.    
    2. Μια υπηρεσία **Azure SQL** συνδεδεμένες για να συνδέσετε τη βάση δεδομένων Azure SQL που περιέχει τα δεδομένα εξόδου. 
3.  Δημιουργία **συνόλων δεδομένων** που περιγράφουν δεδομένα εισόδου και εξόδου δεδομένων για αγωγούς.
4.  Δημιουργηθεί μια **διαδικασία** με μια **Δραστηριότητα αντίγραφο** με **BlobSource** ως προέλευσης και **SqlSink** ως δέκτη.  


## <a name="see-also"></a>Δείτε επίσης
| Το θέμα | Περιγραφή |
| :---- | :---- |
| [Δραστηριότητες κίνηση δεδομένων](data-factory-data-movement-activities.md) | Σε αυτό το άρθρο παρέχει λεπτομερείς πληροφορίες σχετικά με τη δραστηριότητα αντίγραφο που χρησιμοποιούνται στην εκμάθηση. |
| [Προγραμματισμός και εκτέλεσης](data-factory-scheduling-and-execution.md) | Σε αυτό το άρθρο εξηγεί τις προγραμματισμού και εκτέλεσης πτυχές της εργοστασίου δεδομένων Azure μοντέλο εφαρμογών. |
| [Αγωγούς](data-factory-create-pipelines.md) | Σε αυτό το άρθρο σάς βοηθά να κατανοήσετε αγωγούς και δραστηριότητες του Azure εργοστασίου δεδομένων. |
| [Σύνολα δεδομένων](data-factory-create-datasets.md) | Σε αυτό το άρθρο σάς βοηθά να κατανοήσετε συνόλων δεδομένων στην προέλευση δεδομένων Azure.
| [Παρακολούθηση και διαχείριση αγωγούς χρήση της εφαρμογής παρακολούθησης](data-factory-monitor-manage-app.md) | Σε αυτό το άρθρο περιγράφει τον τρόπο για την παρακολούθηση, διαχείριση και εντοπισμός σφαλμάτων αγωγούς με την παρακολούθηση & Διαχείριση εφαρμογών. 


