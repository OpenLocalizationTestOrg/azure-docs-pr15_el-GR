<properties
    pageTitle="Δημιουργία του πρώτου εργοστασίου δεδομένων (Visual Studio) | Microsoft Azure"
    description="Σε αυτό το πρόγραμμα εκμάθησης, μπορείτε να δημιουργήσετε μια διοχέτευση εργοστασίου δεδομένων Azure δείγμα χρήση του Visual Studio."
    services="data-factory"
    documentationCenter=""
    authors="spelluru"
    manager="jhubbard"
    editor="monicar"/>

<tags
    ms.service="data-factory"
    ms.workload="data-services"
    ms.tgt_pltfrm="na"
    ms.devlang="na"
    ms.topic="hero-article" 
    ms.date="10/17/2016"
    ms.author="spelluru"/>

# <a name="tutorial-build-your-azure-first-data-factory-using-microsoft-visual-studio"></a>Πρόγραμμα εκμάθησης: Δημιουργία Azure πρώτη σας δεδομένων εργοστασίου χρησιμοποιώντας το Microsoft Visual Studio
> [AZURE.SELECTOR]
- [Επισκόπηση και τις προϋποθέσεις](data-factory-build-your-first-pipeline.md)
- [Πύλη του Azure](data-factory-build-your-first-pipeline-using-editor.md)
- [Visual Studio](data-factory-build-your-first-pipeline-using-vs.md)
- [PowerShell](data-factory-build-your-first-pipeline-using-powershell.md)
- [Το πρότυπο διαχείρισης πόρων](data-factory-build-your-first-pipeline-using-arm.md)
- [REST API](data-factory-build-your-first-pipeline-using-rest-api.md)

Σε αυτό το άρθρο, μπορείτε να χρησιμοποιήσετε το Microsoft Visual Studio για να δημιουργήσετε το πρώτο εργοστασίου Azure δεδομένων.

## <a name="prerequisites"></a>Προαπαιτούμενα στοιχεία
1. Διαβάστε το άρθρο [Επισκόπηση πρόγραμμα εκμάθησης](data-factory-build-your-first-pipeline.md) και ολοκληρώστε τα βήματα **προϋπόθεση** .
2. Πρέπει να είστε ο **διαχειριστής της συνδρομής Azure** να είναι σε θέση να δημοσιεύσετε οντοτήτων εργοστασίου δεδομένων από το Visual Studio στο Azure δεδομένων Factory.
3. Πρέπει να έχετε εγκαταστήσει στον υπολογιστή σας τα εξής: 
    - Visual Studio 2013 ή του Visual Studio 2015
    - Κάντε λήψη του Azure SDK για Visual Studio 2013 ή του Visual Studio 2015. Μεταβείτε στη [Σελίδα λήψης Azure](https://azure.microsoft.com/downloads/) και κάντε κλικ **και στο 2013** ή **και στο 2015** στην ενότητα **.NET** .
    - Λήψη την πιο πρόσφατη Προσθήκη εργοστασίου δεδομένων Azure για το Visual Studio: [ΣΎΓΚΡΙΣΗ 2013](https://visualstudiogallery.msdn.microsoft.com/754d998c-8f92-4aa7-835b-e89c8c954aa5) ή [και στο 2015](https://visualstudiogallery.msdn.microsoft.com/371a4cf9-0093-40fa-b7dd-be3c74f49005). Μπορείτε επίσης να ενημερώσετε την προσθήκη, κάνοντας τα εξής: στο μενού, κάντε κλικ στην επιλογή **Εργαλεία** -> **επεκτάσεις και ενημερώσεις** -> **Online** -> **Visual Studio συλλογή** -> **Εργαλεία εργοστασίου του Microsoft Azure δεδομένων για το Visual Studio** -> **Ενημέρωση**. 
 
Τώρα, ας χρησιμοποιήσουμε Visual Studio για τη δημιουργία ενός εργοστασίου Azure δεδομένων. 


## <a name="create-visual-studio-project"></a>Δημιουργία έργου Visual Studio 
1. Εκκινήστε το **Visual Studio 2013** ή του **Visual Studio 2015**. Κάντε κλικ στο **αρχείο**, επιλέξτε **Δημιουργία**και κάντε κλικ στο **έργο**. Θα πρέπει να βλέπετε το παράθυρο διαλόγου **Νέο έργο** .  
2. Στο παράθυρο διαλόγου **Νέο έργο** , επιλέξτε το πρότυπο **DataFactory** και κάντε κλικ στην επιλογή **Κενό έργο εργοστασίου δεδομένων**.   

    ![Παράθυρο διαλόγου Δημιουργία έργου](./media/data-factory-build-your-first-pipeline-using-vs/new-project-dialog.png)

3. Πληκτρολογήστε ένα **όνομα** για το έργο, **θέση**και ένα όνομα για τη **λύση**και κάντε κλικ στο κουμπί **OK**.

    ![Εξερεύνηση λύσεων](./media/data-factory-build-your-first-pipeline-using-vs/solution-explorer.png)

## <a name="create-linked-services"></a>Δημιουργία συνδεδεμένων υπηρεσιών
Μια προέλευση δεδομένων μπορεί να έχει ένα ή περισσότερα αγωγούς. Μια διαδικασία μπορεί να έχει μία ή περισσότερες δραστηριότητες σε αυτό. Για παράδειγμα, μια δραστηριότητα Αντιγραφή για να αντιγράψετε δεδομένα από ένα αρχείο προέλευσης για ένα χώρο αποθήκευσης δεδομένων προορισμού και δραστηριότητα HDInsight Hive για να εκτελέσετε Hive δέσμη ενεργειών για τη μετατροπή των δεδομένων εισαγωγής. Ανατρέξτε στο θέμα [αποθηκεύει τις υποστηριζόμενες δεδομένα](data-factory-data-movement-activities.md##supported-data-stores-and-formats) για όλες τις προελεύσεις και δέκτες που υποστηρίζονται από τη δραστηριότητα αντίγραφο. Δείτε [τον υπολογισμό συνδεδεμένες υπηρεσίες](data-factory-compute-linked-services.md) για τη λίστα των υπηρεσιών υπολογισμού υποστηρίζονται από προέλευση δεδομένων. 

Σε αυτό το βήμα, μπορείτε να συνδέσετε το λογαριασμό σας χώρο αποθήκευσης Azure και ένα σύμπλεγμα Azure HDInsight στη ζήτηση για την προέλευση δεδομένων. Ο λογαριασμός Azure αποθήκευσης διατηρεί τα δεδομένα εισόδου και εξόδου για τη διαδικασία σε αυτό το δείγμα. Για να εκτελέσετε Hive δέσμη ενεργειών που καθορίζονται στη δραστηριότητα από τη διαδικασία σε αυτό το δείγμα χρησιμοποιείται η υπηρεσία HDInsight συνδεδεμένες. Προσδιορίστε ποια δεδομένα store/υπολογισμού υπηρεσίες που χρησιμοποιούνται στη δική σας περίπτωση και να συνδέσετε αυτές τις υπηρεσίες η προέλευση δεδομένων δημιουργώντας συνδεδεμένες υπηρεσίες.  

Καθορίστε το όνομα και τις ρυθμίσεις για την προέλευση δεδομένων αργότερα, όταν δημοσιεύετε τη λύση εργοστασίου δεδομένων σας.

#### <a name="create-azure-storage-linked-service"></a>Δημιουργία χώρου αποθήκευσης Azure συνδεδεμένες υπηρεσίας
Σε αυτό το βήμα, μπορείτε να συνδέσετε το λογαριασμό σας χώρο αποθήκευσης Azure για την προέλευση δεδομένων. Για αυτό το πρόγραμμα εκμάθησης, μπορείτε να χρησιμοποιήσετε τον ίδιο λογαριασμό Azure χώρου αποθήκευσης για την αποθήκευση δεδομένων εισόδου/εξόδου και το αρχείο δέσμης ενεργειών HQL. 

4. Κάντε δεξί κλικ **Συνδεδεμένες υπηρεσίες** στην Εξερεύνηση λύσεων, τοποθετήστε το δείκτη για **Προσθήκη**και κάντε κλικ στην επιλογή **Νέο στοιχείο**.      
5. Στο παράθυρο διαλόγου **Προσθήκη νέου στοιχείου** , επιλέξτε **Υπηρεσία αποθήκευσης στο Azure συνδεδεμένων** από τη λίστα και κάντε κλικ στην επιλογή **Προσθήκη**. 
3. Αντικαταστήστε το **όνομα λογαριασμού** και **accountkey** με το όνομα του λογαριασμού Azure χώρου αποθήκευσης και το κλειδί. Για να μάθετε πώς μπορείτε να λάβετε τον αριθμό-κλειδί access χώρου αποθήκευσης, ανατρέξτε στο θέμα [Προβολή "," Αντιγραφή "και" πλήκτρα πρόσβασης regenerate χώρου αποθήκευσης](../storage/storage-create-storage-account.md#view-copy-and-regenerate-storage-access-keys)

    ![Azure αποθήκευσης συνδεδεμένες υπηρεσίας](./media/data-factory-build-your-first-pipeline-using-vs/azure-storage-linked-service.png)

4. Αποθηκεύστε το αρχείο **AzureStorageLinkedService1.json** .

#### <a name="create-azure-hdinsight-linked-service"></a>Δημιουργία Azure HDInsight συνδεδεμένες υπηρεσίας
Σε αυτό το βήμα, μπορείτε να συνδέσετε ένα σύμπλεγμα HDInsight στην απαιτήσεων για την προέλευση δεδομένων. Το HDInsight σύμπλεγμα αυτόματα δημιουργείται κατά το χρόνο εκτέλεσης και διαγραφεί μετά την ολοκλήρωση επεξεργασίας και αδρανής για το καθορισμένο χρονικό διάστημα. Μπορείτε να χρησιμοποιήσετε τη δική σας σύμπλεγμα HDInsight αντί να χρησιμοποιήσετε ένα σύμπλεγμα HDInsight στη ζήτηση. Για λεπτομέρειες, ανατρέξτε στο θέμα [Τον υπολογισμό συνδεδεμένες υπηρεσίες](data-factory-compute-linked-services.md) . 

1. Στην **Εξερεύνηση λύσεων**, κάντε δεξί κλικ **Συνδεδεμένες υπηρεσίες**, τοποθετήστε το δείκτη για **Προσθήκη**και κάντε κλικ στην επιλογή **Νέο στοιχείο**.
2. Επιλέξτε **HDInsight απαιτήσεων συνδεδεμένων της υπηρεσίας**και κάντε κλικ στην επιλογή **Προσθήκη**. 
3. Αντικαταστήστε το **JSON** με τα εξής:

        {
          "name": "HDInsightOnDemandLinkedService",
          "properties": {
            "type": "HDInsightOnDemand",
            "typeProperties": {
              "version": "3.2",
              "clusterSize": 1,
              "timeToLive": "00:30:00",
              "linkedServiceName": "AzureStorageLinkedService1"
            }
          }
        }
    
    Ο παρακάτω πίνακας παρέχει περιγραφές για τις ιδιότητες JSON χρησιμοποιείται σε το τμήμα κώδικα:
    
    Ιδιότητα | Περιγραφή
    -------- | -----------
    Έκδοση | Καθορίζει ότι η δημιουργία έκδοσης της το HDInsight να είναι 3,2. 
    ClusterSize | Καθορίζει το μέγεθος του συμπλέγματος HDInsight. 
    Το TimeToLive | Καθορίζει ότι το χρόνο αδράνειας για το σύμπλεγμα HDInsight, πριν να διαγραφεί.
    linkedServiceName | Καθορίζει το λογαριασμό χώρου αποθήκευσης που χρησιμοποιείται για την αποθήκευση των αρχείων καταγραφής που δημιουργούνται από το HDInsight

    Λάβετε υπόψη τα εξής: 
    
    - Η προέλευση δεδομένων δημιουργεί ένα σύμπλεγμα HDInsight **βασίζεται σε Windows** με το προηγούμενο JSON. Επίσης, μπορείτε να έχετε το Δημιουργήστε ένα σύμπλεγμα HDInsight **βάσει Linux** . Για λεπτομέρειες, ανατρέξτε στο θέμα [On demand HDInsight συνδεδεμένων υπηρεσιών](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) . 
    - Μπορείτε να χρησιμοποιήσετε **τη δική σας σύμπλεγμα HDInsight** αντί να χρησιμοποιήσετε ένα σύμπλεγμα HDInsight στη ζήτηση. Για λεπτομέρειες, ανατρέξτε στο θέμα [Υπηρεσία συνδεδεμένων HDInsight](data-factory-compute-linked-services.md#azure-hdinsight-linked-service) .
    - Το HDInsight σύμπλεγμα δημιουργεί ένα **προεπιλεγμένο κοντέινερ** το χώρο αποθήκευσης αντικειμένων blob που καθορίσατε στο το JSON (**linkedServiceName**). HDInsight δεν διαγράφει αυτό το κοντέινερ όταν διαγράφεται το σύμπλεγμα. Αυτή η συμπεριφορά οφείλεται στη σχεδίαση. Με την υπηρεσία HDInsight συνδεδεμένο σε ζήτηση, δημιουργείται ένα σύμπλεγμα HDInsight κάθε φορά που ένα κομμάτι υποβάλλεται σε επεξεργασία, εκτός εάν υπάρχει ένα υπάρχον σύμπλεγμα ζωντανή (**το timeToLive**). Το σύμπλεγμα διαγράφονται αυτόματα όταν ολοκληρωθεί η επεξεργασία.
    
        Κατά την επεξεργασία περισσότερες φέτες, μπορείτε να δείτε πολλά κοντέινερ στο χώρο αποθήκευσης αντικειμένων blob του Azure του. Εάν δεν χρειάζεστε τους για την αντιμετώπιση προβλημάτων με τις εργασίες, μπορείτε να τα διαγράψετε για να μειώσετε το κόστος χώρου αποθήκευσης. Τα ονόματα από αυτά τα κοντέινερ ακολουθήστε ένα μοτίβο: "adf**yourdatafactoryname**-**linkedservicename**- datetimestamp". Χρήση εργαλείων όπως [Εξερεύνηση χώρου αποθήκευσης](http://storageexplorer.com/) για τη διαγραφή κοντέινερ στο χώρο αποθήκευσης αντικειμένων blob του Azure του.

    Για λεπτομέρειες, ανατρέξτε στο θέμα [On demand HDInsight συνδεδεμένων υπηρεσιών](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) . 
4. Αποθηκεύστε το αρχείο **HDInsightOnDemandLinkedService1.json** .

## <a name="create-datasets"></a>Δημιουργία συνόλων δεδομένων
Σε αυτό το βήμα, δημιουργείτε σύνολα δεδομένων για να αντιπροσωπεύει τα δεδομένα εισόδου και εξόδου δεδομένων για την επεξεργασία της ομάδας. Αυτά τα σύνολα δεδομένων που αναφέρονται σε **AzureStorageLinkedService1** που δημιουργήσατε νωρίτερα σε αυτό το πρόγραμμα εκμάθησης. Τα σημεία συνδεδεμένων υπηρεσιών σε λογαριασμό αποθήκευσης Azure και συνόλων δεδομένων καθορίσετε κοντέινερ, φάκελο, όνομα αρχείου στο χώρο αποθήκευσης της όπου διατηρείται εισόδου και εξόδου δεδομένων.   

#### <a name="create-input-dataset"></a>Δημιουργία συνόλου δεδομένων εισαγωγής

1. Στην **Εξερεύνηση λύσεων**, κάντε δεξί κλικ σε **πίνακες**, τοποθετήστε το δείκτη για **Προσθήκη**και κάντε κλικ στην επιλογή **Νέο στοιχείο**. 
2. Επιλέξτε **Αντικειμένων Blob του Azure** από τη λίστα, αλλάξτε το όνομα του αρχείου σε **InputDataSet.json**και κάντε κλικ στην επιλογή **Προσθήκη**.
3. Αντικαταστήστε το **JSON** στο πρόγραμμα επεξεργασίας με τα εξής: 

    Με το τμήμα κώδικα JSON, θέλετε να δημιουργήσετε ένα σύνολο δεδομένων που ονομάζεται **AzureBlobInput** που αντιπροσωπεύει δεδομένα εισόδου για μια δραστηριότητα στη διοχέτευση. Επιπλέον, μπορείτε να καθορίσετε ότι τα δεδομένα εισόδου βρίσκεται στο κοντέινερ αντικειμένων blob που ονομάζεται **adfgetstarted** και στο φάκελο που ονομάζεται **inputdata**
        
        {
            "name": "AzureBlobInput",
            "properties": {
                "type": "AzureBlob",
                "linkedServiceName": "AzureStorageLinkedService1",
                "typeProperties": {
                    "fileName": "input.log",
                    "folderPath": "adfgetstarted/inputdata",
                    "format": {
                        "type": "TextFormat",
                        "columnDelimiter": ","
                    }
                },
                "availability": {
                    "frequency": "Month",
                    "interval": 1
                },
                "external": true,
                "policy": {}
            }
        } 

    Ο παρακάτω πίνακας παρέχει περιγραφές για τις ιδιότητες JSON χρησιμοποιείται σε το τμήμα κώδικα:

  	| Ιδιότητα | Περιγραφή |
  	| :------- | :---------- |
  	| Τύπος | Η ιδιότητα τύπος έχει οριστεί σε AzureBlob επειδή βρίσκονται στο χώρο αποθήκευσης αντικειμένων blob του Azure δεδομένα. |  
  	| linkedServiceName | αναφέρεται το AzureStorageLinkedService1 που δημιουργήσατε νωρίτερα. |
  	| όνομα αρχείου | Αυτή η ιδιότητα είναι προαιρετικό. Εάν παραλείψετε αυτή την ιδιότητα, όλα τα αρχεία από το folderPath έχουν συλλεχθεί. Σε αυτήν την περίπτωση, γίνεται επεξεργασία μόνο το input.log. |
  	| Τύπος | Τα αρχεία καταγραφής είναι σε μορφή κειμένου, ώστε να χρησιμοποιήσουμε TextFormat. | 
  	| Διαχωριστικό_στήλης | στήλες στα αρχεία καταγραφής είναι ορίζεται από το κόμμα () |
  	| συχνότητα/διάστημα | συχνότητα ρυθμιστεί μήνα και διάστημα είναι 1, το οποίο σημαίνει ότι τις φέτες του εισόδου είναι διαθέσιμες κάθε μήνα. | 
  	| εξωτερική | Αυτή η ιδιότητα έχει οριστεί στην τιμή true αν τα δεδομένα εισόδου δεν δημιουργείται από την υπηρεσία εργοστασίου δεδομένων. | 
      
    
3. Αποθηκεύστε το αρχείο **InputDataset.json** . 

 
#### <a name="create-output-dataset"></a>Δημιουργία συνόλου δεδομένων εξόδου
Τώρα, μπορείτε να δημιουργήσετε το σύνολο δεδομένων εξόδου για να αντιπροσωπεύει τα δεδομένα εξόδου που είναι αποθηκευμένα σε το χώρο αποθήκευσης αντικειμένων Blob του Azure. 

1. Στην **Εξερεύνηση λύσεων**, κάντε δεξί κλικ σε **πίνακες**, τοποθετήστε το δείκτη για **Προσθήκη**και κάντε κλικ στην επιλογή **Νέο στοιχείο**. 
2. Επιλέξτε **Αντικειμένων Blob του Azure** από τη λίστα, αλλάξτε το όνομα του αρχείου σε **OutputDataset.json**και κάντε κλικ στην επιλογή **Προσθήκη**. 
3. Αντικαταστήστε το **JSON** στο πρόγραμμα επεξεργασίας με τα εξής: 

    Με το τμήμα κώδικα JSON, θέλετε να δημιουργήσετε ένα σύνολο δεδομένων που ονομάζεται **AzureBlobOutput**και καθορίζοντας τη δομή των δεδομένων που παράγεται από τη δέσμη ενεργειών της ομάδας. Επιπλέον, μπορείτε να καθορίσετε ότι τα αποτελέσματα είναι αποθηκευμένα στο κοντέινερ αντικειμένων blob που ονομάζεται **adfgetstarted** και στο φάκελο που ονομάζεται **partitioneddata**. Στην ενότητα **διαθεσιμότητα** Καθορίζει ότι το σύνολο δεδομένων εξόδου παράγεται σε μηνιαία βάση.
    
        {
          "name": "AzureBlobOutput",
          "properties": {
            "type": "AzureBlob",
            "linkedServiceName": "AzureStorageLinkedService1",
            "typeProperties": {
              "folderPath": "adfgetstarted/partitioneddata",
              "format": {
                "type": "TextFormat",
                "columnDelimiter": ","
              }
            },
            "availability": {
              "frequency": "Month",
              "interval": 1
            }
          }
        }

    Ανατρέξτε στην ενότητα **Δημιουργία του συνόλου δεδομένων εισόδου** για περιγραφές από αυτές τις ιδιότητες. Δεν ορίζετε την ιδιότητα εξωτερικών σε ένα σύνολο δεδομένων εξόδου που παράγεται από την υπηρεσία εργοστασίου δεδομένων του συνόλου δεδομένων.

4. Αποθηκεύστε το αρχείο **OutputDataset.json** .


### <a name="create-pipeline"></a>Δημιουργία διοχέτευσης
Σε αυτό το βήμα, μπορείτε να δημιουργήσετε το πρώτο διοχέτευσης με μια δραστηριότητα **HDInsightHive** . Στη φέτα εισόδου είναι διαθέσιμη κάθε μήνα (συχνότητα: μήνα, διάστημα: 1), φέτα εξόδου παράγεται μηνιαία και είναι επίσης να ορίσετε την ιδιότητα χρονοδιαγράμματος για τη δραστηριότητα σε μηνιαία. Πρέπει να συμφωνεί με τις ρυθμίσεις για το σύνολο δεδομένων εξόδου και το Χρονοδιάγραμμα δραστηριότητας. Προς το παρόν, σύνολο δεδομένων εξόδου είναι τι κατευθύνει το χρονοδιάγραμμα, ώστε να πρέπει να δημιουργήσετε ένα σύνολο δεδομένων εξόδου ακόμα και αν τη δραστηριότητα δεν παράγει κανένα αποτέλεσμα. Εάν η δραστηριότητα μην απαιτηθεί οποιαδήποτε εισαγωγή, μπορείτε να παραλείψετε τη δημιουργία του συνόλου δεδομένων εισόδου. Οι ιδιότητες που χρησιμοποιούνται στο το παρακάτω JSON εξηγούνται στο τέλος αυτής της ενότητας.

1. Στην **Εξερεύνηση λύσεων**, κάντε δεξί κλικ **αγωγούς**, τοποθετήστε το δείκτη για **Προσθήκη**και κάντε κλικ στην επιλογή **νέο στοιχείο.** 
2. Επιλέξτε **Hive διοχέτευσης μετασχηματισμό** από τη λίστα και κάντε κλικ στην επιλογή **Προσθήκη**. 
3. Αντικαταστήστε το **JSON** με το παρακάτω τμήμα κώδικα.

    > [AZURE.IMPORTANT] Αντικαταστήστε **storageaccountname** με το όνομα του λογαριασμού χώρου αποθήκευσης.

        {
            "name": "MyFirstPipeline",
            "properties": {
                "description": "My first Azure Data Factory pipeline",
                "activities": [
                    {
                        "type": "HDInsightHive",
                        "typeProperties": {
                            "scriptPath": "adfgetstarted/script/partitionweblogs.hql",
                            "scriptLinkedService": "AzureStorageLinkedService1",
                            "defines": {
                                "inputtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/inputdata",
                                "partitionedtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/partitioneddata"
                            }
                        },
                        "inputs": [
                            {
                                "name": "AzureBlobInput"
                            }
                        ],
                        "outputs": [
                            {
                                "name": "AzureBlobOutput"
                            }
                        ],
                        "policy": {
                            "concurrency": 1,
                            "retry": 3
                        },
                        "scheduler": {
                            "frequency": "Month",
                            "interval": 1
                        },
                        "name": "RunSampleHiveActivity",
                        "linkedServiceName": "HDInsightOnDemandLinkedService"
                    }
                ],
                "start": "2016-04-01T00:00:00Z",
                "end": "2016-04-02T00:00:00Z",
                "isPaused": false
            }
        }

    Με το τμήμα κώδικα JSON, θέλετε να δημιουργήσετε μια διαδικασία που αποτελείται από μια μεμονωμένη δραστηριότητα που χρησιμοποιεί Hive στη διαδικασία δεδομένων σε ένα σύμπλεγμα HDInsight.
    
    Με το τμήμα κώδικα JSON, θέλετε να δημιουργήσετε μια διαδικασία που αποτελείται από μια μεμονωμένη δραστηριότητα που χρησιμοποιεί Hive στη διαδικασία δεδομένων σε ένα σύμπλεγμα HDInsight.
    
    Το αρχείο δέσμης ενεργειών της ομάδας, **partitionweblogs.hql**, αποθηκεύεται στο ο λογαριασμός Azure χώρου αποθήκευσης (που καθορίζεται από το scriptLinkedService, που ονομάζεται **AzureStorageLinkedService1**) και στο φάκελο **δέσμης ενεργειών** σε το κοντέινερ **adfgetstarted**.

    Η ενότητα **ορίζει** χρησιμοποιείται για να καθορίσετε τις ρυθμίσεις χρόνου εκτέλεσης που μεταβιβάζονται στη δέσμη ενεργειών hive ως τιμές παραμέτρων Hive (π.χ. ${hiveconf: inputtable}, {hiveconf:partitionedtable} $).

    Τις ιδιότητες **Έναρξη** και **Λήξη** της διοχέτευσης Καθορίζει την ενεργή περίοδο της διοχέτευσης.

    Στη δραστηριότητα JSON, μπορείτε να καθορίσετε ότι η δέσμη ενεργειών Hive εκτελείται σε του υπολογισμού που καθορίζεται από το **linkedServiceName** – **HDInsightOnDemandLinkedService**.

    > [AZURE.NOTE] Για λεπτομέρειες σχετικά με τις ιδιότητες JSON που χρησιμοποιείται στο παράδειγμα, ανατρέξτε στο θέμα [Ανατομία μια διαδικασία](data-factory-create-pipelines.md#anatomy-of-a-pipeline) . 
3. Αποθηκεύστε το αρχείο **HiveActivity1.json** .

### <a name="add-partitionweblogshql-and-inputlog-as-a-dependency"></a>Προσθήκη partitionweblogs.hql και input.log ως εξάρτηση 

1. Κάντε δεξί κλικ στο παράθυρο **Εξερεύνηση λύσεων** **εξαρτήσεις** , τοποθετήστε το δείκτη για **Προσθήκη**και κάντε κλικ στην επιλογή **Υπάρχον στοιχείο**.  
2. Μεταβείτε το **C:\ADFGettingStarted** επιλέξτε **partitionweblogs.hql**, **input.log** αρχεία, και κάντε κλικ στην επιλογή **Προσθήκη**. Είχατε δημιουργήσει αυτά τα δύο αρχεία ως μέρος του προαπαιτούμενα στοιχεία από το [Πρόγραμμα εκμάθησης Επισκόπηση](data-factory-build-your-first-pipeline.md).

Κατά τη δημοσίευση της λύσης στο επόμενο βήμα, το αρχείο **partitionweblogs.hql** αποστέλλεται στο φάκελο δέσμης ενεργειών στο κοντέινερ αντικειμένων blob **adfgetstarted** .   

### <a name="publishdeploy-data-factory-entities"></a>Δημοσίευση/ανάπτυξη οντοτήτων εργοστασίου δεδομένων

18. Κάντε δεξί κλικ έργου στην Εξερεύνηση λύσεων και κάντε κλικ στο κουμπί **Δημοσίευση**. 
19. Εάν βλέπετε το παράθυρο διαλόγου **Είσοδος στο λογαριασμό Microsoft** , εισαγάγετε τα διαπιστευτήριά σας για το λογαριασμό που έχει συνδρομή Azure και κάντε κλικ στην επιλογή **Είσοδος**.
20. Θα πρέπει να βλέπετε το παρακάτω παράθυρο διαλόγου:

    ![Παράθυρο διαλόγου δημοσίευση](./media/data-factory-build-your-first-pipeline-using-vs/publish.png)

21. Στη σελίδα Ρύθμιση παραμέτρων δεδομένων εργοστασίου, κάντε τα εξής: 
    1. Ορίστε την επιλογή **Δημιουργία νέου εργοστασίου δεδομένων** .
    2. Πληκτρολογήστε ένα μοναδικό **όνομα** για την προέλευση δεδομένων. Για παράδειγμα: **FirstDataFactoryUsingVS09152016**. Το όνομα πρέπει να είναι μοναδικό καθολικό.  
    
    
        > [AZURE.IMPORTANT] Εάν εμφανιστεί το σφάλμα **όνομα εργοστασίου δεδομένων "FirstDataFactoryUsingVS" δεν είναι διαθέσιμη** κατά τη δημοσίευση, αλλάξτε το όνομα (για παράδειγμα, yournameFirstDataFactoryUsingVS). Ανατρέξτε στο θέμα [Factory δεδομένων - κανόνες ονοματοθεσίας](data-factory-naming-rules.md) για τους κανόνες ονοματοθεσίας για αντικείμενα εργοστασίου δεδομένων.
3. Επιλέξτε τη σωστή συνδρομή για το πεδίο **συνδρομής** .
     
     
        > [AZURE.IMPORTANT] Εάν δεν βλέπετε καμία συνδρομή, βεβαιωθείτε ότι έχετε συνδεθεί χρησιμοποιώντας ένα λογαριασμό που είναι ένα διαχειριστή ή από κοινού-διαχείριση της συνδρομής.  
        
    4. Επιλέξτε την **ομάδα πόρων** για την εργοστασίου δεδομένων που θα δημιουργηθεί. 
    5. Επιλέξτε την **περιοχή** για την προέλευση δεδομένων. 
    6. Κάντε κλικ στο κουμπί **Επόμενο** για να μεταβείτε στη σελίδα **Δημοσίευση στοιχείων** . (Πατήστε το πλήκτρο **TAB** για να μετακινηθείτε από το πεδίο "όνομα" για να εάν είναι απενεργοποιημένο το κουμπί " **Επόμενο** ".) 
23. Στη σελίδα **Δημοσίευση στοιχείων** , βεβαιωθείτε ότι όλα τα εργοστάσια δεδομένων οντοτήτων είναι επιλεγμένα και κάντε κλικ στο κουμπί **Επόμενο** για να μεταβείτε στη σελίδα **Σύνοψη** .     
24. Ελέγξτε τη σύνοψη και κάντε κλικ στο κουμπί **Επόμενο** για να ξεκινήσετε τη διαδικασία ανάπτυξης και προβολή της **Κατάστασης ανάπτυξης**.
25. Στη σελίδα **Κατάσταση ανάπτυξης** , θα πρέπει να βλέπετε την κατάσταση της διαδικασίας ανάπτυξης. Μόλις ολοκληρωθεί η ανάπτυξη, κάντε κλικ στο κουμπί Τέλος. 

 
Σημαντικά σημεία για να λάβετε υπόψη: 

- Εάν λαμβάνετε το μήνυμα σφάλματος: "**Αυτή η συνδρομή δεν έχει καταχωρηθεί για να χρησιμοποιήσετε το χώρο ονομάτων Microsoft.DataFactory**", κάντε ένα από τα παρακάτω και προσπαθήστε να δημοσιεύσετε ξανά: 

    - Στο Azure PowerShell, εκτελέστε την ακόλουθη εντολή για να καταχωρήσετε την υπηρεσία παροχής δεδομένων Factory. 
        
            Register-AzureRmResourceProvider -ProviderNamespace Microsoft.DataFactory
    
        Μπορείτε να εκτελέσετε την παρακάτω εντολή για να επιβεβαιώσετε ότι η προέλευση δεδομένων έχει καταχωρηθεί η υπηρεσία παροχής που χρησιμοποιείτε. 
    
            Get-AzureRmResourceProvider
    - Συνδεθείτε χρησιμοποιώντας το Azure συνδρομή στο [Azure πύλη](https://portal.azure.com) και μεταβείτε σε μια blade εργοστασίου δεδομένων (ή) Δημιουργήστε μια προέλευση δεδομένων στην πύλη του Azure. Αυτή η ενέργεια καταχωρεί αυτόματα την υπηρεσία παροχής για εσάς.
-   Το όνομα του εργοστασίου δεδομένων μπορεί να έχει εγγραφεί ως όνομα DNS στο μέλλον και συνεπώς γίνονται δημόσια ορατά.
-   Για να δημιουργήσετε παρουσίες εργοστασίου δεδομένων, πρέπει να είναι ένα διαχειριστή ή από κοινού διαχειριστές της συνδρομής Azure

 
## <a name="monitor-pipeline"></a>Οθόνη διοχέτευσης

### <a name="monitor-pipeline-using-diagram-view"></a>Οθόνη διοχέτευσης χρησιμοποιώντας την προβολή διαγράμματος
6. Συνδεθείτε [πύλη του Azure](https://portal.azure.com/), κάντε τα εξής:
    1. Κάντε κλικ στην επιλογή **περισσότερες υπηρεσίες** και κάντε κλικ στην επιλογή **εργοστάσια δεδομένων**.
        ![Αναζήτηση εργοστάσια δεδομένων](./media/data-factory-build-your-first-pipeline-using-vs/browse-datafactories.png) 
    2. Επιλέξτε το όνομα του εργοστασίου δεδομένων σας (για παράδειγμα: **FirstDataFactoryUsingVS09152016**) από τη λίστα των εργοστάσια δεδομένων. 
        ![Επιλέξτε την προέλευση δεδομένων](./media/data-factory-build-your-first-pipeline-using-vs/select-first-data-factory.png)
7. Στην αρχική σελίδα για την προέλευση δεδομένων, κάντε κλικ στο **διάγραμμα**.
  
    ![Πλακίδιο του διαγράμματος](./media/data-factory-build-your-first-pipeline-using-vs/diagram-tile.png)
7. Στην προβολή διαγράμματος, μπορείτε να δείτε μια επισκόπηση των αγωγών και των συνόλων δεδομένων που χρησιμοποιούνται σε αυτό το πρόγραμμα εκμάθησης.
    
    ![Προβολή διαγράμματος](./media/data-factory-build-your-first-pipeline-using-vs/diagram-view-2.png) 
8. Για να προβάλετε όλες τις δραστηριότητες της διοχέτευσης, κάντε δεξί κλικ διοχέτευσης στο διάγραμμα και κάντε κλικ στην επιλογή Άνοιγμα διοχέτευσης. 

    ![Άνοιγμα διοχέτευσης μενού](./media/data-factory-build-your-first-pipeline-using-vs/open-pipeline-menu.png)
9. Επιβεβαιώστε ότι μπορείτε να δείτε τη δραστηριότητα HDInsightHive στη διοχέτευση. 
  
    ![Άνοιγμα διοχέτευσης προβολή](./media/data-factory-build-your-first-pipeline-using-vs/open-pipeline-view.png)

    Για να επιστρέψετε στην προηγούμενη προβολή, κάντε κλικ στην επιλογή **προέλευση δεδομένων** στο μενού δυναμικής διαδρομής στο επάνω μέρος. 
10. Στην **Προβολή "Διάγραμμα"**, κάντε διπλό κλικ του συνόλου δεδομένων **AzureBlobInput**. Επιβεβαιώστε ότι η φέτα είναι σε κατάσταση **είστε έτοιμοι** . Ενδέχεται να χρειαστούν μερικά λεπτά για τη φέτα ώστε να εμφανίζεται σε κατάσταση είστε έτοιμοι. Εάν δεν εκτελεστεί μετά περιμένετε κάποια στιγμή, ανατρέξτε στο θέμα εάν έχετε το αρχείο εισόδου (input.log) τοποθετείται στο φάκελο (inputdata) and δεξιά κοντέινερ (adfgetstarted).

    ![Εισαγωγής φέτα έτοιμη κατάσταση](./media/data-factory-build-your-first-pipeline-using-vs/input-slice-ready.png)
11. Κάντε κλικ στο **X** για να κλείσετε **AzureBlobInput** blade. 
12. Στην **Προβολή "Διάγραμμα"**, κάντε διπλό κλικ του συνόλου δεδομένων **AzureBlobOutput**. Που βλέπετε στη φέτα που υποβάλλεται σε επεξεργασία.

    ![Σύνολο δεδομένων](./media/data-factory-build-your-first-pipeline-using-vs/dataset-blade.png)
9. Όταν ολοκληρωθεί η επεξεργασία, μπορείτε να δείτε τη φέτα **έτοιμη** κατάσταση.

    > [AZURE.IMPORTANT] Η δημιουργία ένα σύμπλεγμα HDInsight σε ζήτηση συνήθως χρειάζεται κάποια στιγμή (περίπου 20 λεπτά). Επομένως, περιμένετε τη διαδικασία για να **περιέχει έως και 30 λεπτά** για την επεξεργασία στη φέτα.  

    ![Σύνολο δεδομένων](./media/data-factory-build-your-first-pipeline-using-vs/dataset-slice-ready.png) 
    
10. Όταν στη φέτα βρίσκεται σε κατάσταση **είστε έτοιμοι** , ελέγξτε το φάκελο **partitioneddata** στο κοντέινερ **adfgetstarted** στο χώρο αποθήκευσης αντικειμένων blob του για τα δεδομένα εξόδου.  
 
    ![δεδομένα εξόδου](./media/data-factory-build-your-first-pipeline-using-vs/three-ouptut-files.png)
11. Κάντε κλικ στη φέτα για να δείτε λεπτομέρειες σχετικά με αυτήν σε ένα **κομμάτι δεδομένων** blade.

    ![Λεπτομέρειες φέτα δεδομένων](./media/data-factory-build-your-first-pipeline-using-vs/data-slice-details.png)  
12. Κάντε κλικ στην επιλογή μιας δραστηριότητας εκτέλεση στη **λίστα εκτελείται δραστηριότητας** για να δείτε λεπτομέρειες σχετικά με μια δραστηριότητα Εκτέλεση (Hive δραστηριότητα σε σενάριο μας) σε ένα παράθυρο **δραστηριότητας εκτέλεση λεπτομέρειες** .   
    ![Εκτέλεση λεπτομέρειες δραστηριότητας](./media/data-factory-build-your-first-pipeline-using-vs/activity-window-blade.png)  
    
    Από τα αρχεία καταγραφής, μπορείτε να δείτε το ερώτημα Hive που εκτελέστηκε και οι πληροφορίες κατάστασης. Αυτά τα αρχεία καταγραφής είναι χρήσιμη για την αντιμετώπιση τυχόν προβλημάτων.  
 

Ανατρέξτε στο θέμα [οθόνη συνόλων δεδομένων και διαδικασία](data-factory-monitor-manage-pipelines.md) για οδηγίες σχετικά με τον τρόπο για να χρησιμοποιήσουν την πύλη του Azure για την παρακολούθηση των και συνόλων δεδομένων που δημιουργήσατε σε αυτό το πρόγραμμα εκμάθησης.

### <a name="monitor-pipeline-using-monitor--manage-app"></a>Παρακολούθηση της διοχέτευσης με οθόνη & Διαχείριση εφαρμογών
Μπορείτε επίσης να χρησιμοποιείτε οθόνη & Διαχείριση εφαρμογών για την παρακολούθηση της σας αγωγούς. Για λεπτομερείς πληροφορίες σχετικά με τη χρήση αυτής της εφαρμογής, ανατρέξτε στο θέμα [οθόνη και να διαχειριστείτε αγωγούς εργοστασίου δεδομένων Azure χρησιμοποιώντας παρακολούθησης και διαχείρισης εφαρμογών](data-factory-monitor-manage-app.md).

1. Κάντε κλικ στην επιλογή παρακολούθηση και διαχείριση πλακίδιο.

    ![Παρακολούθηση και διαχείριση πλακιδίων](./media/data-factory-build-your-first-pipeline-using-vs/monitor-and-manage-tile.png) 
2. Που θα πρέπει να δείτε: Εποπτεία & Διαχείριση εφαρμογών. Αλλάξτε **την ώρα έναρξης** και **ώρα λήξης** ώστε να ταιριάζει με Έναρξη (04-01-2016 12:00 πμ) και λήξης (04-02-2016 12:00 πμ) της διοχέτευσης σας, και κάντε κλικ στο κουμπί **εφαρμογή**.

    ![Παρακολούθηση και διαχείριση εφαρμογών](./media/data-factory-build-your-first-pipeline-using-vs/monitor-and-manage-app.png) 
3. Επιλέξτε ένα παράθυρο δραστηριότητα στη λίστα των Windows δραστηριότητας για να δείτε λεπτομέρειες σχετικά με αυτήν. 
    ![Λεπτομέρειες παραθύρου δραστηριότητα](./media/data-factory-build-your-first-pipeline-using-vs/activity-window-details.png)


> [AZURE.IMPORTANT] Το αρχείο εισαγωγής λαμβάνει διαγραφεί κατά τη φέτα υποβάλλεται σε επεξεργασία με επιτυχία. Επομένως, εάν θέλετε να εκτελέσετε ξανά στη φέτα ή κάντε ξανά το πρόγραμμα εκμάθησης, στείλτε το αρχείο εισόδου (input.log) στο φάκελο inputdata του κοντέινερ adfgetstarted.
 

## <a name="use-server-explorer-to-view-data-factories"></a>Χρησιμοποιήστε την Εξερεύνηση διακομιστή για την προβολή δεδομένων εργοστάσια

1. Στο **Visual Studio**, κάντε κλικ στην επιλογή " **Προβολή** " στο μενού και κάντε κλικ στην επιλογή **Εξερεύνηση Server**.
2. Στο παράθυρο της Εξερεύνησης διακομιστή, αναπτύξτε **Azure** και αναπτύξτε **Εργοστασίου δεδομένων**. Εάν βλέπετε **να εισέλθετε στο Visual Studio**, εισαγάγετε το **λογαριασμό** που σχετίζεται με τη συνδρομή σας στο Azure και κάντε κλικ στην επιλογή **Continue**. Πληκτρολογήστε **τον κωδικό πρόσβασης**και κάντε κλικ στην επιλογή **Είσοδος**. Visual Studio προσπαθεί να λάβετε πληροφορίες σχετικά με όλα εργοστάσια Azure δεδομένων στη συνδρομή σας. Μπορείτε να δείτε την κατάσταση αυτής της λειτουργίας στο παράθυρο **Δεδομένων λίστας εργασιών Factory** .

    ![Εξερεύνηση Server](./media/data-factory-build-your-first-pipeline-using-vs/server-explorer.png)
3. Μπορείτε να κάντε δεξί κλικ σε μια προέλευση δεδομένων και επιλέξτε **Εξαγωγή δεδομένων Factory στο νέο έργο** για να δημιουργήσετε ένα έργο Visual Studio που βασίζεται σε μια υπάρχουσα εργοστασίου δεδομένων.

    ![Εξαγωγή δεδομένων factory](./media/data-factory-build-your-first-pipeline-using-vs/export-data-factory-menu.png)

## <a name="update-data-factory-tools-for-visual-studio"></a>Ενημέρωση Εργαλεία εργοστασίου δεδομένων για το Visual Studio

Για να ενημερώσετε Εργαλεία εργοστασίου δεδομένων Azure για το Visual Studio, κάντε τα εξής:

1. Κάντε κλικ στην επιλογή " **Εργαλεία** " στο μενού και επιλέξτε **επεκτάσεις και ενημερώσεις**.
2. Επιλέξτε τις **ενημερώσεις** στο αριστερό τμήμα του παραθύρου και, στη συνέχεια, επιλέξτε **Visual Studio συλλογή**.
3. Επιλέξτε **Εργαλεία εργοστασίου δεδομένων Azure για το Visual Studio** και κάντε κλικ στην επιλογή **Ενημέρωση**. Εάν δεν βλέπετε αυτήν την εγγραφή, έχετε ήδη την πιο πρόσφατη έκδοση των εργαλείων. 

## <a name="use-configuration-files"></a>Χρήση αρχείων ρύθμισης παραμέτρων
Μπορείτε να χρησιμοποιήσετε αρχεία ρύθμισης παραμέτρων στο Visual Studio για να ρυθμίσετε τις παραμέτρους ιδιοτήτων για τις συνδεδεμένες υπηρεσίες/πίνακες/αγωγούς διαφορετικά για κάθε περιβάλλον. 

Εξετάστε τον ακόλουθο ορισμό JSON για μια υπηρεσία αποθήκευσης Azure συνδεδεμένες. Για να καθορίσετε τη **συμβολοσειρά σύνδεσης** με διαφορετικές τιμές για το όνομα λογαριασμού και accountkey που βασίζεται στο περιβάλλον (δοκιμής/ανάπτυξης/παραγωγή) στην οποία αναπτύσσετε οντοτήτων εργοστασίου δεδομένων. Μπορείτε να επιτύχετε αυτήν τη συμπεριφορά χρησιμοποιώντας το αρχείο ρύθμισης παραμέτρων ξεχωριστά για κάθε περιβάλλον. 

    {
        "name": "StorageLinkedService",
        "properties": {
            "type": "AzureStorage",
            "description": "",
            "typeProperties": {
                "connectionString": "DefaultEndpointsProtocol=https;AccountName=<accountname>;AccountKey=<accountkey>"
            }
        }
    } 

### <a name="add-a-configuration-file"></a>Προσθήκη ενός αρχείου ρύθμισης παραμέτρων
Προσθέστε ένα αρχείο ρύθμισης παραμέτρων για κάθε περιβάλλον, ακολουθώντας τα παρακάτω βήματα:   

1. Κάντε δεξί κλικ στο έργο εργοστασίου δεδομένων στη λύση σας Visual Studio, τοποθετήστε το δείκτη για **Προσθήκη**και κάντε κλικ στην επιλογή **νέο στοιχείο**.
2. Επιλογή **ρύθμισης παραμέτρων** από τη λίστα των εγκατεστημένων προτύπων στα αριστερά, επιλέξτε **Αρχείο ρύθμισης παραμέτρων**, πληκτρολογήστε ένα **όνομα** για το αρχείο ρύθμισης παραμέτρων και κάντε κλικ στην επιλογή **Προσθήκη**.

    ![Προσθήκη αρχείου ρύθμισης παραμέτρων](./media/data-factory-build-your-first-pipeline-using-vs/add-config-file.png)
3. Προσθέστε παραμέτρους και τις τιμές τους με την εξής μορφή.

        {
            "$schema": "http://datafactories.schema.management.azure.com/vsschemas/V1/Microsoft.DataFactory.Config.json",
            "AzureStorageLinkedService1": [
                {
                    "name": "$.properties.typeProperties.connectionString",
                    "value": "DefaultEndpointsProtocol=https;AccountName=<accountname>;AccountKey=<accountkey>"
                }
            ],
            "AzureSqlLinkedService1": [
                {
                    "name": "$.properties.typeProperties.connectionString",
                    "value":  "Server=tcp:spsqlserver.database.windows.net,1433;Database=spsqldb;User ID=spelluru;Password=Sowmya123;Trusted_Connection=False;Encrypt=True;Connection Timeout=30"
                }
            ]
        }

    Αυτό το παράδειγμα ρυθμίζει τις παραμέτρους ιδιότητα συμβολοσειρά σύνδεσης του μια υπηρεσία αποθήκευσης Azure συνδεδεμένες και μια υπηρεσία SQL Azure συνδεδεμένες. Παρατηρήστε ότι η σύνταξη για να καθορίσετε το όνομα είναι [JsonPath](http://goessner.net/articles/JsonPath/).   

    Εάν JSON έχει μια ιδιότητα που περιέχει έναν πίνακα τιμών, όπως φαίνεται στο ακόλουθο κώδικα:  

        "structure": [
            {
                "name": "FirstName",
                "type": "String"
            },
            {
                "name": "LastName",
                "type": "String"
            }
        ],
    
    Ρύθμιση παραμέτρων ιδιοτήτων, όπως φαίνεται στο παρακάτω αρχείο ρύθμισης παραμέτρων (χρήση ως βάση το μηδέν δημιουργίας ευρετηρίου): 
        
        {
            "name": "$.properties.structure[0].name",
            "value": "FirstName"
        }
        {
            "name": "$.properties.structure[0].type",
            "value": "String"
        }
        {
            "name": "$.properties.structure[1].name",
            "value": "LastName"
        }
        {
            "name": "$.properties.structure[1].type",
            "value": "String"
        }

### <a name="property-names-with-spaces"></a>Τα ονόματα των ιδιοτήτων με διαστήματα
Εάν ένα όνομα ιδιότητας περιέχει κενά διαστήματα, χρησιμοποιήστε αγκύλες, όπως φαίνεται στο παρακάτω παράδειγμα (όνομα διακομιστή βάσης δεδομένων): 

     {
         "name": "$.properties.activities[1].typeProperties.webServiceParameters.['Database server name']",
         "value": "MyAsqlServer.database.windows.net"
     }


### <a name="deploy-solution-using-a-configuration"></a>Ανάπτυξη της λύσης χρησιμοποιώντας μια ρύθμιση παραμέτρων
Όταν δημοσιεύετε εργοστασίου δεδομένων Azure οντοτήτων στο και στο, μπορείτε να καθορίσετε τη ρύθμιση παραμέτρων που θέλετε να χρησιμοποιήσετε για αυτήν τη λειτουργία δημοσίευσης. 

Για να δημοσιεύσετε οντοτήτων σε ένα έργο Azure εργοστασίου δεδομένων χρησιμοποιώντας το αρχείο ρύθμισης παραμέτρων:   

1. Κάντε δεξί κλικ εργοστασίου δεδομένων έργου και κάντε κλικ στην επιλογή **Δημοσίευση** για να δείτε το παράθυρο διαλόγου **Δημοσίευση στοιχείων** . 
2. Επιλέξτε μια υπάρχουσα εργοστασίου δεδομένων ή καθορίστε τιμές για τη δημιουργία ενός εργοστασίου δεδομένων στη σελίδα **Ρύθμιση παραμέτρων εργοστασίου δεδομένων** και κάντε κλικ στο κουμπί **Επόμενο**.   
3. Στη σελίδα **Δημοσίευση στοιχείων** : βλέπετε μια αναπτυσσόμενη λίστα με τις διαθέσιμες ρυθμίσεις παραμέτρων για το πεδίο **Επιλέξτε ρύθμισης παραμέτρων ανάπτυξης** .

    ![Επιλέξτε αρχείο ρύθμισης παραμέτρων](./media/data-factory-build-your-first-pipeline-using-vs/select-config-file.png)

4. Επιλέξτε το **αρχείο ρύθμισης παραμέτρων** που θέλετε να χρησιμοποιήσετε και κάντε κλικ στο κουμπί **Επόμενο**. 
5. Βεβαιωθείτε ότι βλέπετε το όνομα του αρχείου JSON στη σελίδα **Σύνοψη** και κάντε κλικ στο κουμπί **Επόμενο**. 
6. Αφού ολοκληρωθεί η λειτουργία ανάπτυξη, κάντε κλικ στο κουμπί **Τέλος** . 

Κατά την ανάπτυξη, τις τιμές από το αρχείο ρύθμισης παραμέτρων χρησιμοποιούνται για να ορίσετε τιμές για τις ιδιότητες των αρχείων JSON για οντοτήτων εργοστασίου δεδομένων πριν από το οντοτήτων αναπτύσσονται εργοστασίου δεδομένων Azure υπηρεσία.   

## <a name="summary"></a>Σύνοψη 
Σε αυτό το πρόγραμμα εκμάθησης, δημιουργήσατε ένα εργοστασίου Azure δεδομένων την επεξεργασία δεδομένων, εκτελώντας Hive δέσμης ενεργειών σε ένα σύμπλεγμα hadoop HDInsight. Χρησιμοποιήσατε το πρόγραμμα επεξεργασίας εργοστασίου δεδομένων στην πύλη του Azure για να εκτελέσετε τα παρακάτω βήματα:  

1.  Δημιουργία μιας Azure **εργοστασίου δεδομένων**.
2.  Δημιουργία δύο **συνδεδεμένες υπηρεσίες**:
    1.  Υπηρεσία **Αποθήκευσης azure** συνδεδεμένες για να συνδέσετε το χώρο αποθήκευσης αντικειμένων blob του Azure που περιέχει τα αρχεία εισόδου/εξόδου για την προέλευση δεδομένων.
    2.  **Azure HDInsight** σε ζήτηση συνδεδεμένων υπηρεσία για να συνδέσετε ένα σύμπλεγμα HDInsight Hadoop σε ζήτηση με την προέλευση δεδομένων. Azure εργοστασίου δεδομένων δημιουργεί μια HDInsight Hadoop σύμπλεγμα απλώς-σε-ώρα για την επεξεργασία δεδομένων εισόδου και να παραγάγετε δεδομένα εξόδου. 
3.  Δημιουργία δύο **συνόλων δεδομένων**, που περιγράφουν δεδομένα εισόδου και εξόδου για ομάδα HDInsight δραστηριότητα στη διοχέτευση. 
4.  Δημιουργία μιας **διοχέτευσης** με μια δραστηριότητα **HDInsight Hive** .  


## <a name="next-steps"></a>Επόμενα βήματα
Σε αυτό το άρθρο, έχετε δημιουργήσει μια διαδικασία με μια δραστηριότητα μετασχηματισμού (HDInsight δραστηριότητα) που εκτελεί μια δέσμη ενεργειών της ομάδας σε ένα σύμπλεγμα HDInsight στη ζήτηση. Για να δείτε πώς μπορείτε να χρησιμοποιήσετε μια δραστηριότητα Αντιγραφή για να αντιγράψετε δεδομένα από ένα αντικειμένων Blob του Azure Azure SQL, ανατρέξτε στο θέμα [πρόγραμμα εκμάθησης: αντιγραφή δεδομένων από μια Azure αντικειμένων blob σε Azure SQL](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).
  
## <a name="see-also"></a>Δείτε επίσης
| Το θέμα | Περιγραφή |
| :---- | :---- |
| [Δραστηριότητες μετασχηματισμού δεδομένων](data-factory-data-transformation-activities.md) | Σε αυτό το άρθρο παρέχει μια λίστα των δραστηριοτήτων μετασχηματισμό δεδομένων (όπως το HDInsight Hive μετασχηματισμό που χρησιμοποιείται σε αυτό το πρόγραμμα εκμάθησης) υποστηρίζονται από το Azure εργοστασίου δεδομένων. | 
| [Προγραμματισμός και εκτέλεσης](data-factory-scheduling-and-execution.md) | Σε αυτό το άρθρο εξηγεί τις προγραμματισμού και εκτέλεσης πτυχές της εργοστασίου δεδομένων Azure μοντέλο εφαρμογών. |
| [Αγωγούς](data-factory-create-pipelines.md) | Σε αυτό το άρθρο σάς βοηθά να κατανοήσετε αγωγούς και δραστηριοτήτων στις εργοστασιακές δεδομένων Azure και πώς να τους χρησιμοποιήσετε για να δημιουργήσετε ολοκληρωμένες να βασίζονται σε δεδομένα ροές εργασίας για το σενάριο ή επιχειρήσεις. |
| [Σύνολα δεδομένων](data-factory-create-datasets.md) | Σε αυτό το άρθρο σάς βοηθά να κατανοήσετε συνόλων δεδομένων στην προέλευση δεδομένων Azure.
| [Παρακολούθηση και διαχείριση αγωγούς χρήση της εφαρμογής παρακολούθησης](data-factory-monitor-manage-app.md) | Σε αυτό το άρθρο περιγράφει τον τρόπο για την παρακολούθηση, διαχείριση και εντοπισμός σφαλμάτων αγωγούς με την παρακολούθηση & Διαχείριση εφαρμογών. 
