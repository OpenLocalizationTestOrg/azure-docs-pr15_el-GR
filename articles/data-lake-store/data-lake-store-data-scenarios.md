<properties 
   pageTitle="Σενάρια δεδομένα που αφορούν χώρου αποθήκευσης δεδομένων λίμνης | Microsoft Azure" 
   description="Κατανόηση της διαφορετικά σενάρια και τα εργαλεία με τα δεδομένα που μπορούν να κατάποση, υποβάλλονται σε επεξεργασία, λήψη και απεικονιστούν σε ένα χώρο αποθήκευσης δεδομένων λίμνης" 
   services="data-lake-store" 
   documentationCenter="" 
   authors="nitinme" 
   manager="jhubbard" 
   editor="cgronlun"/>
 
<tags
   ms.service="data-lake-store"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="big-data" 
   ms.date="09/06/2016"
   ms.author="nitinme"/>

# <a name="using-azure-data-lake-store-for-big-data-requirements"></a>Με χρήση του χώρου αποθήκευσης λίμνης δεδομένων Azure για απαιτήσεις μεγάλο δεδομένων

Υπάρχουν τέσσερις βασικές σταδίων σε μεγάλο επεξεργασίας δεδομένων:

* Ingesting μεγάλες ποσότητες δεδομένων σε ένα χώρο αποθήκευσης δεδομένων, σε πραγματικό χρόνο ή σε δέσμες
* Επεξεργασία των δεδομένων
* Γίνεται λήψη των δεδομένων
* Απεικόνιση των δεδομένων

Σε αυτό το άρθρο εξετάσουμε αυτά τα στάδια σε σχέση με Azure χώρου αποθήκευσης λίμνης δεδομένων για να κατανοήσετε τις επιλογές και εργαλεία που είναι διαθέσιμα για τις ανάγκες σας μεγάλο δεδομένων.

## <a name="ingest-data-into-data-lake-store"></a>Ingest δεδομένων στο χώρο αποθήκευσης δεδομένων λίμνης

Αυτή η ενότητα επισημαίνει τις διαφορετικές προελεύσεις δεδομένων και τους διαφορετικούς τρόπους με την οποία μπορούν να κατάποση αυτά τα δεδομένα σε ένα λογαριασμό του χώρου αποθήκευσης δεδομένων λίμνης.

![Ingest δεδομένων στο χώρο αποθήκευσης δεδομένων λίμνης] (./media/data-lake-store-data-scenarios/ingest-data.png "Ingest δεδομένων στο χώρο αποθήκευσης δεδομένων λίμνης")

### <a name="ad-hoc-data"></a>Ad hoc δεδομένων

Αυτό αντιπροσωπεύει μικρότερο σύνολα δεδομένων που είναι χρησιμοποιείται για τη δημιουργία πρωτοτύπων μια εφαρμογή μεγάλο δεδομένων. Υπάρχουν διάφοροι τρόποι ingesting ad hoc δεδομένων ανάλογα με την προέλευση των δεδομένων.

| Αρχείο προέλευσης δεδομένων        | Ingest χρησιμοποιώντας                                                                        |
|--------------------|----------------------------------------------------------------------------------------|
| Τοπικό υπολογιστή     | <ul> <li>[Πύλη του Azure](/data-lake-store-get-started-portal.md)</li> <li>[Azure PowerShell](data-lake-store-get-started-powershell.md)</li> <li>[Azure CLI πλατφόρμες](data-lake-store-get-started-cli.md)</li> <li>[Χρήση των εργαλείων λίμνης δεδομένων για το Visual Studio](../data-lake-analytics/data-lake-analytics-data-lake-tools-get-started.md#upload-source-data-files) </li></ul> |
| Azure χώρο αποθήκευσης αντικειμένων Blob | <ul> <li>[Εργοστασιακές Azure δεδομένων](../data-factory/data-factory-azure-datalake-connector.md#sample-copy-data-from-azure-blob-to-azure-data-lake-store)</li> <li>[Εργαλείο AdlCopy](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[Εκτέλεση σε σύμπλεγμα HDInsight DistCp](data-lake-store-copy-data-wasb-distcp.md)</li> </ul> |

 
### <a name="streamed-data"></a>Ροή δεδομένων

Αυτό αντιπροσωπεύει τα δεδομένα που μπορεί να δημιουργηθεί από διάφορες προελεύσεις, όπως εφαρμογές, τις συσκευές, αισθητήρες, κ.λπ. Αυτά τα δεδομένα να είναι κατάποση σε ένα χώρο αποθήκευσης λίμνης δεδομένων με διάφορα εργαλεία. Αυτά τα εργαλεία θα συνήθως καταγραφή και επεξεργασίας των δεδομένων σε βάση με συμβάντος σε πραγματικό χρόνο, και, στη συνέχεια, συντάξτε τα συμβάντα σε δέσμες στο χώρο αποθήκευσης λίμνης δεδομένων ώστε να τους μπορεί να γίνει περαιτέρω επεξεργασία. 

Ακολουθούν εργαλεία που μπορείτε να χρησιμοποιήσετε:
 
* [Azure ροή ανάλυση] (.. / ροή-ανάλυση-δεδομένων-λίμνης-εξόδου) - συμβάντα κατάποση σε διανομείς συμβάν μπορεί να εγγραφεί στο Azure λίμνης δεδομένων χρησιμοποιώντας το αποτέλεσμα χώρου αποθήκευσης λίμνης Azure δεδομένων.
* [Azure HDInsight καταιγίδας](../hdinsight/hdinsight-storm-write-data-lake-store.md) - μπορείτε να γράψετε δεδομένων απευθείας στο χώρο αποθήκευσης λίμνης δεδομένων από το σύμπλεγμα καταιγίδας.
* [EventProcessorHost](../event-hubs/event-hubs-csharp-ephcs-getstarted.md#receive-messages-with-eventprocessorhost) – μπορείτε να λαμβάνετε συμβάντων από διανομείς συμβάν και, στη συνέχεια, συντάξτε το χώρο αποθήκευσης λίμνης δεδομένων χρησιμοποιώντας το [.NET αποθήκευσης δεδομένων λίμνης SDK](data-lake-store-get-started-net-sdk.md).

### <a name="relational-data"></a>Σχεσιακών δεδομένων

Μπορείτε επίσης να προέλευσης δεδομένων από σχεσιακές βάσεις δεδομένων. Σε μια χρονική περίοδο, σχεσιακές βάσεις δεδομένων συλλογής τεράστιες ποσότητες δεδομένων που μπορούν να παρέχουν βασικές ιδέες εάν υποβάλλονται σε επεξεργασία μέσω μιας διοχέτευσης μεγάλο δεδομένων. Μπορείτε να χρησιμοποιήσετε τα παρακάτω εργαλεία για να μετακινήσετε τα δεδομένα στο χώρο αποθήκευσης λίμνης δεδομένων.

* [Apache Sqoop](data-lake-store-data-transfer-sql-sqoop.md)
* [Εργοστασιακές Azure δεδομένων](../data-factory/data-factory-data-movement-activities.md)

### <a name="web-server-log-data-upload-using-custom-applications"></a>Δεδομένα του αρχείου καταγραφής διακομιστή Web (αποστολή με χρήση προσαρμοσμένων εφαρμογών)

Αυτόν τον τύπο του συνόλου δεδομένων ονομάζεται συγκεκριμένα, επειδή η ανάλυση των δεδομένων αρχείου καταγραφής διακομιστή web είναι μια συνηθισμένη περίπτωση χρήση για εφαρμογές μεγάλο δεδομένων και απαιτεί μεγάλους όγκους των αρχείων καταγραφής να αποσταλεί στο χώρο αποθήκευσης λίμνης δεδομένων. Μπορείτε να χρησιμοποιήσετε οποιοδήποτε από τα παρακάτω εργαλεία για να γράψετε το δικό σας δέσμης ενεργειών ή εφαρμογών για να αποστείλετε τα δεδομένα αυτά.

* [Azure CLI πλατφόρμες](data-lake-store-get-started-cli.md)
* [Azure PowerShell](data-lake-store-get-started-powershell.md)
* [Χώρος αποθήκευσης λίμνης Azure δεδομένων .NET SDK](data-lake-store-get-started-net-sdk.md)
* [Εργοστασιακές Azure δεδομένων](../data-factory/data-factory-data-movement-activities.md)

Για την αποστολή δεδομένων καταγραφής διακομιστή web, καθώς και για αποστολή άλλα είδη δεδομένα (π.χ. κοινωνικών sentiments δεδομένα), είναι μια καλή προσέγγιση για να γράψετε τις δικές σας προσαρμοσμένες δέσμες ενεργειών/εφαρμογές, επειδή σας δίνει την ευελιξία να συμπεριλάβετε τα δεδομένα σας αποστολή στοιχείου ως μέρος της εφαρμογής σας μεγαλύτερο μεγάλο δεδομένων. Σε ορισμένες περιπτώσεις αυτόν τον κωδικό ενδέχεται να χρειαστούν μορφή μια δέσμη ενεργειών ή βοηθητικό πρόγραμμα απλό γραμμής εντολών. Σε άλλες περιπτώσεις, ο κώδικας μπορεί να χρησιμοποιηθούν για την ενσωμάτωση μεγάλο επεξεργασίας δεδομένων σε μια επιχειρηματική εφαρμογή ή μια λύση.


### <a name="data-associated-with-azure-hdinsight-clusters"></a>Δεδομένα που σχετίζονται με συμπλεγμάτων Azure HDInsight

Οι περισσότεροι τύποι σύμπλεγμα HDInsight (Hadoop, HBase, καταιγίδας) υποστηρίζει χώρου αποθήκευσης δεδομένων λίμνης ως ένα αποθετήριο δεδομένων χώρου αποθήκευσης. HDInsight συμπλεγμάτων πρόσβαση στα δεδομένα από το Azure χώρο αποθήκευσης αντικειμένων blob (WASB). Για καλύτερες επιδόσεις, μπορείτε να αντιγράψετε τα δεδομένα από WASB σε λογαριασμό του χώρου αποθήκευσης λίμνης δεδομένων που σχετίζονται με το σύμπλεγμα. Μπορείτε να χρησιμοποιήσετε τα παρακάτω εργαλεία για να αντιγράψετε τα δεδομένα.

* [Apache DistCp](data-lake-store-copy-data-wasb-distcp.md)
* [Υπηρεσία AdlCopy](data-lake-store-copy-data-azure-storage-blob.md)
* [Εργοστασιακές Azure δεδομένων](../data-factory/data-factory-azure-datalake-connector.md#sample-copy-data-from-azure-blob-to-azure-data-lake-store)

### <a name="data-stored-in-on-premise-or-iaas-hadoop-clusters"></a>Τα δεδομένα αποθηκεύονται σε εσωτερική εγκατάσταση ή IaaS Hadoop συμπλεγμάτων

Μεγάλες ποσότητες δεδομένων μπορεί να είναι αποθηκευμένα στην υπάρχουσα συμπλεγμάτων Hadoop, τοπικά σε υπολογιστές με χρήση HDFS. Των συμπλεγμάτων Hadoop μπορεί να είναι σε μια ανάπτυξη εσωτερικής εγκατάστασης ή μπορεί να είναι μέσα σε ένα σύμπλεγμα IaaS στην Azure. Ενδέχεται να υπάρχουν απαιτήσεις για να αντιγράψετε τα δεδομένα αυτά χώρου αποθήκευσης λίμνης Azure δεδομένων για μια μη επαναλαμβανόμενες προσέγγιση ή σε μια περιοδική τρόπο. Υπάρχουν διάφορες επιλογές που μπορείτε να χρησιμοποιήσετε για να επιτύχετε το εξής. Ακολουθεί μια λίστα με εναλλακτικές λύσεις και το σχετικό τα ανταλλάγματα.

| Προσέγγιση  | Λεπτομέρειες | Τα πλεονεκτήματα   | Ζητήματα  |
|-----------|---------|--------------|-----------------|
| Χρήση εργοστασίου δεδομένων Azure (ADF) για να αντιγράψετε τα δεδομένα απευθείας από Hadoop συμπλεγμάτων στο χώρο αποθήκευσης λίμνης δεδομένων Azure | [ADF υποστηρίζει HDFS ως προέλευση δεδομένων](../data-factory/data-factory-hdfs-connector.md) | ADF παρέχει υποστήριξη εκτός του πλαισίου για HDFS και κατηγορίες first class--τελικών διαχείρισης και παρακολούθηση | Απαιτεί πύλη διαχείρισης δεδομένων για να αναπτυχθούν εσωτερική ή στο σύμπλεγμα IaaS |
| Εξαγωγή δεδομένων από Hadoop ως αρχεία. Στη συνέχεια, αντιγράψτε τα αρχεία χρησιμοποιώντας κατάλληλο μηχανισμό χώρου αποθήκευσης λίμνης δεδομένων Azure.                                   | Μπορείτε να αντιγράψετε τα αρχεία με τη χρήση του χώρου αποθήκευσης λίμνης Azure δεδομένων: <ul><li>[Του PowerShell για το λειτουργικό σύστημα Windows Azure](data-lake-store-get-started-powershell.md)</li><li>[Azure πλατφόρμες CLI για μη - λειτουργικού Συστήματος των Windows](data-lake-store-get-started-cli.md)</li><li>Προσαρμοσμένη εφαρμογή χρησιμοποιώντας οποιαδήποτε δεδομένα λίμνης Store SDK</li></ul> | Γρήγορη για να ξεκινήσετε. Να κάνετε προσαρμοσμένων αποστολές                                                   | Διαδικασία πολλών βημάτων που περιλαμβάνει πολλές τεχνολογίες. Διαχείριση και την παρακολούθηση θα αυξηθεί να είναι δύσκολο σταδιακά δεδομένης της προσαρμοσμένης τα εργαλεία |
| Χρησιμοποιήστε Distcp για να αντιγράψετε δεδομένα από Hadoop στο χώρο αποθήκευσης Azure. Στη συνέχεια, αντιγράψτε δεδομένα από το χώρο αποθήκευσης Azure χώρου αποθήκευσης λίμνης δεδομένων με χρήση κατάλληλου μηχανισμού. | Μπορείτε να αντιγράψετε δεδομένα από το χώρο αποθήκευσης Azure με τη χρήση του χώρου αποθήκευσης λίμνης δεδομένων: <ul><li>[Εργοστασιακές Azure δεδομένων](../data-factory/data-factory-data-movement-activities.md)</li><li>[Εργαλείο AdlCopy](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[DistCp Apache εκτελείται σε HDInsight συμπλεγμάτων](data-lake-store-copy-data-wasb-distcp.md)</li></ul>| Μπορείτε να χρησιμοποιήσετε εργαλεία Άνοιγμα προέλευσης. | Διαδικασία πολλών βημάτων που περιλαμβάνει πολλές τεχνολογίες |

### <a name="really-large-datasets"></a>Πραγματικά μεγάλων συνόλων δεδομένων

Για αποστολή συνόλων δεδομένων που περιοχής σε διάφορες terabytes, χρησιμοποιώντας τις μεθόδους που περιγράφονται παραπάνω μπορεί να μερικές φορές είναι αργή και κοστίζουν. Σε αυτές τις περιπτώσεις, μπορείτε να χρησιμοποιήσετε τις παρακάτω επιλογές.

* **Χρήση του Azure ExpressRoute**. Azure ExpressRoute σάς επιτρέπει να δημιουργήσετε ιδιωτικές συνδέσεις μεταξύ Azure κέντρα δεδομένων και την υποδομή στις εγκαταστάσεις σας. Παρέχει μια αξιόπιστη επιλογή για τη μεταφορά μεγάλες ποσότητες δεδομένων. Για περισσότερες πληροφορίες, ανατρέξτε [στην τεκμηρίωση Azure ExpressRoute](../expressroute/expressroute-introduction.md).


* **"Χωρίς σύνδεση" Αποστολή των δεδομένων**. Εάν χρησιμοποιείτε Azure ExpressRoute δεν είναι εφικτό για οποιονδήποτε λόγο, μπορείτε να χρησιμοποιήσετε την [υπηρεσία Azure εισαγωγή/εξαγωγή](../storage/storage-import-export-service.md) για την αποστολή μονάδες σκληρού δίσκου με τα δεδομένα σας σε ένα κέντρο δεδομένων Azure. Τα δεδομένα σας είναι πρώτα που έχουν αποσταλεί με αντικείμενα blob του Azure χώρου αποθήκευσης. Μπορείτε να χρησιμοποιήσετε, στη συνέχεια, [Εργοστασίου δεδομένων Azure](../data-factory/data-factory-azure-datalake-connector.md#sample-copy-data-from-azure-blob-to-azure-data-lake-store) ή [AdlCopy εργαλείο](data-lake-store-copy-data-azure-storage-blob.md) για να αντιγράψετε δεδομένα από αντικείμενα blob του Azure χώρου αποθήκευσης στο χώρο αποθήκευσης λίμνης δεδομένων.

    >[AZURE.NOTE] Ενώ με την υπηρεσία εισαγωγής/εξαγωγής, τα μεγέθη αρχείων των δίσκων που αποστέλλετε κέντρο Azure δεδομένων δεν πρέπει να είναι μεγαλύτερη από 200 GB.


## <a name="process-data-stored-in-data-lake-store"></a>Επεξεργασία δεδομένων που είναι αποθηκευμένα στο χώρο αποθήκευσης δεδομένων λίμνης

Όταν τα δεδομένα είναι διαθέσιμο στο χώρο αποθήκευσης λίμνης δεδομένων μπορείτε να εκτελέσετε ανάλυση σε αυτά τα δεδομένα με τις εφαρμογές υποστηριζόμενες μεγάλο δεδομένων. Προς το παρόν, μπορείτε να χρησιμοποιήσετε για να εκτελέσετε εργασίες ανάλυσης δεδομένων για τα δεδομένα που είναι αποθηκευμένα στο χώρο αποθήκευσης δεδομένων λίμνης Azure HDInsight και τις αναλύσεις λίμνης Azure δεδομένων. 

![Ανάλυση δεδομένων στο χώρο αποθήκευσης δεδομένων λίμνης] (./media/data-lake-store-data-scenarios/analyze-data.png "Ανάλυση δεδομένων στο χώρο αποθήκευσης δεδομένων λίμνης")

Μπορείτε να δείτε τα παρακάτω παραδείγματα.

* [Δημιουργήστε ένα σύμπλεγμα HDInsight με το χώρο αποθήκευσης δεδομένων λίμνης ως χώρου αποθήκευσης](data-lake-store-hdinsight-hadoop-use-portal.md)
* [Χρήση ανάλυσης λίμνης Azure δεδομένων με το χώρο αποθήκευσης δεδομένων λίμνης](../data-lake-analytics/data-lake-analytics-get-started-portal.md)



## <a name="download-data-from-data-lake-store"></a>Λήψη δεδομένων από το χώρο αποθήκευσης δεδομένων λίμνης

Μπορεί επίσης να θέλετε να κάνετε λήψη ή μετακίνηση δεδομένων από το χώρο αποθήκευσης λίμνης δεδομένων Azure για σενάρια, όπως:

* Μετακίνηση δεδομένων σε άλλα αποθετήρια για αλληλεπίδραση με τις υπάρχουσες αγωγούς επεξεργασίας δεδομένων. Για παράδειγμα, μπορεί να θέλετε να μετακινήσετε δεδομένα από χώρο αποθήκευσης λίμνης δεδομένων σε βάση δεδομένων SQL Azure ή SQL Server εσωτερικής εγκατάστασης.
* Λήψη δεδομένων στον τοπικό σας υπολογιστή για επεξεργασία σε περιβάλλοντα IDE κατά τη δημιουργία πρωτοτύπων εφαρμογής.

![Τα δεδομένα εξόδου από χώρο αποθήκευσης δεδομένων λίμνης] (./media/data-lake-store-data-scenarios/egress-data.png "Τα δεδομένα εξόδου από χώρο αποθήκευσης δεδομένων λίμνης")

Σε αυτές τις περιπτώσεις, μπορείτε να χρησιμοποιήσετε οποιαδήποτε από τις ακόλουθες επιλογές:

* [Apache Sqoop](data-lake-store-data-transfer-sql-sqoop.md)
* [Εργοστασιακές Azure δεδομένων](../data-factory/data-factory-data-movement-activities.md)
* [Apache DistCp](data-lake-store-copy-data-wasb-distcp.md)

Μπορείτε επίσης να χρησιμοποιήσετε τις παρακάτω μεθόδους για να γράψετε τη δική σας εφαρμογή/δέσμη ενεργειών για τη λήψη δεδομένων από το χώρο αποθήκευσης λίμνης δεδομένων.

* [Azure CLI πλατφόρμες](data-lake-store-get-started-cli.md)
* [Azure PowerShell](data-lake-store-get-started-powershell.md)
* [Χώρος αποθήκευσης λίμνης Azure δεδομένων .NET SDK](data-lake-store-get-started-net-sdk.md)

## <a name="visualize-data-in-data-lake-store"></a>Απεικόνιση δεδομένων στο χώρο αποθήκευσης δεδομένων λίμνης

Μπορείτε να χρησιμοποιήσετε ένα συνδυασμό και των υπηρεσιών για να δημιουργήσετε οπτικές αναπαραστάσεις των δεδομένων που είναι αποθηκευμένα στο χώρο αποθήκευσης λίμνης δεδομένων.

![Αναπαράσταση δεδομένων στο χώρο αποθήκευσης δεδομένων λίμνης] (./media/data-lake-store-data-scenarios/visualize-data.png "Αναπαράσταση δεδομένων στο χώρο αποθήκευσης δεδομένων λίμνης")

* Μπορείτε να ξεκινήσετε με τη χρήση [Azure εργοστασίου δεδομένων για τη μετακίνηση δεδομένων από το χώρο αποθήκευσης δεδομένων λίμνης αποθήκη δεδομένων SQL Azure](../data-factory/data-factory-data-movement-activities.md#supported-data-stores)
* Μετά από αυτό, μπορείτε να [ενοποιήσετε το Power BI με αποθήκη δεδομένων του SQL Azure](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) για να δημιουργήσετε οπτική αναπαράσταση των δεδομένων.
